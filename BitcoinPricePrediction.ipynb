{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846585c2",
   "metadata": {},
   "source": [
    "# Bitcoin Price Prediction Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3406cd",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5d6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the libraries needed to work with the project here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import datetime\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62c0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read bitcoin pricing CSV into dataframe\n",
    "btc_prices = pd.read_csv('bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c271f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert unix timestamps to date-time\n",
    "btc_prices['Timestamp'] = pd.to_datetime(btc_prices['Timestamp'], unit='s')\n",
    "btc_prices = btc_prices.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88cf75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_(BTC)</th>\n",
       "      <th>Volume_(Currency)</th>\n",
       "      <th>Weighted_Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:51:00</th>\n",
       "      <td>58677.05</td>\n",
       "      <td>58699.90</td>\n",
       "      <td>58660.00</td>\n",
       "      <td>58699.90</td>\n",
       "      <td>2.672676</td>\n",
       "      <td>156832.692130</td>\n",
       "      <td>58680.021260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:52:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:53:00</th>\n",
       "      <td>58718.68</td>\n",
       "      <td>58731.23</td>\n",
       "      <td>58698.34</td>\n",
       "      <td>58698.50</td>\n",
       "      <td>0.207983</td>\n",
       "      <td>12209.055282</td>\n",
       "      <td>58702.294657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:54:00</th>\n",
       "      <td>58736.19</td>\n",
       "      <td>58762.43</td>\n",
       "      <td>58736.19</td>\n",
       "      <td>58739.95</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>2441.376572</td>\n",
       "      <td>58745.145351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:55:00</th>\n",
       "      <td>58742.18</td>\n",
       "      <td>58742.18</td>\n",
       "      <td>58714.31</td>\n",
       "      <td>58714.31</td>\n",
       "      <td>2.519999</td>\n",
       "      <td>148004.448110</td>\n",
       "      <td>58731.946927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:56:00</th>\n",
       "      <td>58714.31</td>\n",
       "      <td>58714.31</td>\n",
       "      <td>58686.00</td>\n",
       "      <td>58686.00</td>\n",
       "      <td>1.384487</td>\n",
       "      <td>81259.372187</td>\n",
       "      <td>58692.753339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:57:00</th>\n",
       "      <td>58683.97</td>\n",
       "      <td>58693.43</td>\n",
       "      <td>58683.97</td>\n",
       "      <td>58685.81</td>\n",
       "      <td>7.294848</td>\n",
       "      <td>428158.146640</td>\n",
       "      <td>58693.226508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:58:00</th>\n",
       "      <td>58693.43</td>\n",
       "      <td>58723.84</td>\n",
       "      <td>58693.43</td>\n",
       "      <td>58723.84</td>\n",
       "      <td>1.705682</td>\n",
       "      <td>100117.070370</td>\n",
       "      <td>58696.198496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30 23:59:00</th>\n",
       "      <td>58742.18</td>\n",
       "      <td>58770.38</td>\n",
       "      <td>58742.18</td>\n",
       "      <td>58760.59</td>\n",
       "      <td>0.720415</td>\n",
       "      <td>42332.958633</td>\n",
       "      <td>58761.866202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31 00:00:00</th>\n",
       "      <td>58767.75</td>\n",
       "      <td>58778.18</td>\n",
       "      <td>58755.97</td>\n",
       "      <td>58778.18</td>\n",
       "      <td>2.712831</td>\n",
       "      <td>159417.751000</td>\n",
       "      <td>58764.349363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low     Close  Volume_(BTC)  \\\n",
       "Timestamp                                                                   \n",
       "2021-03-30 23:51:00  58677.05  58699.90  58660.00  58699.90      2.672676   \n",
       "2021-03-30 23:52:00       NaN       NaN       NaN       NaN           NaN   \n",
       "2021-03-30 23:53:00  58718.68  58731.23  58698.34  58698.50      0.207983   \n",
       "2021-03-30 23:54:00  58736.19  58762.43  58736.19  58739.95      0.041559   \n",
       "2021-03-30 23:55:00  58742.18  58742.18  58714.31  58714.31      2.519999   \n",
       "2021-03-30 23:56:00  58714.31  58714.31  58686.00  58686.00      1.384487   \n",
       "2021-03-30 23:57:00  58683.97  58693.43  58683.97  58685.81      7.294848   \n",
       "2021-03-30 23:58:00  58693.43  58723.84  58693.43  58723.84      1.705682   \n",
       "2021-03-30 23:59:00  58742.18  58770.38  58742.18  58760.59      0.720415   \n",
       "2021-03-31 00:00:00  58767.75  58778.18  58755.97  58778.18      2.712831   \n",
       "\n",
       "                     Volume_(Currency)  Weighted_Price  \n",
       "Timestamp                                               \n",
       "2021-03-30 23:51:00      156832.692130    58680.021260  \n",
       "2021-03-30 23:52:00                NaN             NaN  \n",
       "2021-03-30 23:53:00       12209.055282    58702.294657  \n",
       "2021-03-30 23:54:00        2441.376572    58745.145351  \n",
       "2021-03-30 23:55:00      148004.448110    58731.946927  \n",
       "2021-03-30 23:56:00       81259.372187    58692.753339  \n",
       "2021-03-30 23:57:00      428158.146640    58693.226508  \n",
       "2021-03-30 23:58:00      100117.070370    58696.198496  \n",
       "2021-03-30 23:59:00       42332.958633    58761.866202  \n",
       "2021-03-31 00:00:00      159417.751000    58764.349363  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_prices.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c84a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price statistics: \n",
      "average:  6008.93 $\n",
      "median:   3596.80 $\n",
      "minimum:     3.80 $\n",
      "maximum: 61716.21 $\n"
     ]
    }
   ],
   "source": [
    "btc_average = btc_prices['Weighted_Price'].mean()\n",
    "btc_median = btc_prices['Weighted_Price'].median()\n",
    "btc_min = btc_prices['Weighted_Price'].min()\n",
    "btc_max = btc_prices['Weighted_Price'].max()\n",
    "\n",
    "print('Price statistics: ')\n",
    "print('average:  {0:.2f} $'.format(btc_average))\n",
    "print('median:   {0:.2f} $'.format(btc_median))\n",
    "print('minimum:     {0:.2f} $'.format(btc_min))\n",
    "print('maximum: {0:.2f} $'.format(btc_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3ad18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill the rows with NaN prices\n",
    "cleaned_btc_prices = btc_prices.fillna(method=\"ffill\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820c380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove not needed columns\n",
    "cleaned_btc_prices = cleaned_btc_prices.drop(['Open', 'Close', 'Volume_(Currency)', 'Volume_(BTC)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bceeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample prices to resolution of one price per hour and pad missing values with next valid one\n",
    "resampled_btc_prices = cleaned_btc_prices.resample('1D').mean().pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c1268af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the resulting graph of BTC prices in time\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "resampled_btc_prices['Weighted_Price'].plot()\n",
    "plt.ylabel('BTC Price [USD]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2adff2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the resulting graph of BTC prices in time (log scale)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "resampled_btc_prices['Weighted_Price'].plot()\n",
    "plt.ylabel('BTC Price [USD]')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a47a1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store resampled and cleaned records to file\n",
    "resampled_btc_prices.to_csv('cleaned_resampled_btc_prices.csv',index_label='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b63e9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned and resampled BTC prices\n",
    "btc_prices = resampled_btc_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d290d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert to JSON LD format which is needed for DeepAR\n",
    "def timeseries_to_json_ld(df, column_index, excluded_context_length):\n",
    "    return { \n",
    "        \"start\": df.index[0].strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "        \"target\": df.iloc[:df.shape[0] - excluded_context_length, column_index].to_numpy().tolist()\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "59c21dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create test and training JSON file for deepAR\n",
    "columns = btc_prices.shape[1]\n",
    "\n",
    "def write_dataframe_to_deep_AR_json_ld(df, file_name, excluded_context_length=0):\n",
    "    with open(file_name, 'a') as json_file:\n",
    "        for column_index in range(columns):\n",
    "            json_line = json.dumps(timeseries_to_json_ld(df, column_index, excluded_context_length)) + '\\n'\n",
    "            json_file.write(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "72affcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction length, lets make it 1 month\n",
    "prediction_length = 30\n",
    "\n",
    "# context length, lets make it 2 months\n",
    "context_length = prediction_length * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b47f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset with complete data (as recommended in deepAR best practices)\n",
    "write_dataframe_to_deep_AR_json_ld(btc_prices, 'data/test.json')\n",
    "\n",
    "# create training dataset with complete data minus the prediction lenght (as recommended in deepAR best practices)\n",
    "write_dataframe_to_deep_AR_json_ld(btc_prices, 'data/train.json', prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e13698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sagemaker session, role and default S3 bucket\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e610ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix='bitcoin-prediction'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "# upload training and test dataset to S3\n",
    "train_path  = session.upload_data('data/train.json', bucket=bucket, key_prefix=train_prefix)\n",
    "test_path   = session.upload_data('data/test.json',  bucket=bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b0df222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training location: s3://sagemaker-us-east-1-237845067016/bitcoin-prediction/train/train.json\n",
      "Test location: s3://sagemaker-us-east-1-237845067016/bitcoin-prediction/test/test.json\n"
     ]
    }
   ],
   "source": [
    "print('Training location: '+ train_path)\n",
    "print('Test location: '+ test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5507553",
   "metadata": {},
   "source": [
    "## 2. Creating and Training the deepAR Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0b3e009f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "# create an estimator instance for deepAR\n",
    "image_uri = get_image_uri(boto3.Session().region_name, \"forecasting-deepar\")\n",
    "s3_output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=session,\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    base_job_name=\"bitcoin-predictor\",\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e77c9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set good hyper parameters\n",
    "\n",
    "frequency = 'D' # 1 day frequency\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": frequency,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"100\",\n",
    "    \"num_layers\": \"6\",\n",
    "    \"likelihood\": \"student-T\",\n",
    "    \"epochs\": \"200\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    # \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.15\",\n",
    "    \"early_stopping_patience\": \"40\"\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5b3d32c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-26 15:00:19 Starting - Starting the training job...ProfilerReport-1635260419: InProgress\n",
      "......\n",
      "2021-10-26 15:01:34 Starting - Launching requested ML instances...............\n",
      "2021-10-26 15:04:20 Starting - Preparing the instances for training...............\n",
      "2021-10-26 15:06:34 Downloading - Downloading input data\n",
      "2021-10-26 15:06:34 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'prediction_length': '30', 'dropout_rate': '0.15', 'time_freq': 'D', 'likelihood': 'gaussian', 'context_length': '60', 'num_layers': '7', 'epochs': '200', 'learning_rate': '0.0003', 'early_stopping_patience': '40', 'mini_batch_size': '32', 'num_cells': '100'}\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.15', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.0003', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '100', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '7', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'prediction_length': '30', 'time_freq': 'D', 'context_length': '60', 'epochs': '200'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] random_seed is None\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Training set statistics:\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Real time series\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] number of time series: 3\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] number of observations: 10047\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] mean target length: 3349.0\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] min/mean/max target: 4.328902721405029/4151.404100726585/57071.52734375\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] mean abs(target): 4151.404100726585\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] contains missing values: no\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Small number of time series. Doing 107 passes over dataset with prob 0.9968847352024922 per epoch.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Test set statistics:\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Real time series\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] number of time series: 3\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] number of observations: 10137\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] mean target length: 3379.0\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] min/mean/max target: 4.328902721405029/4601.723784157049/60490.421875\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] mean abs(target): 4601.723784157049\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] contains missing values: no\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] #memory_usage::<batchbuffer> = 12.597084045410156 mb\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] nvidia-smi took: 0.02530980110168457 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:02 INFO 139626503206272] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260822.8820012, \"EndTime\": 1635260823.4337554, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 548.9797592163086, \"count\": 1, \"min\": 548.9797592163086, \"max\": 548.9797592163086}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:03 INFO 139626503206272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:04 INFO 139626503206272] #memory_usage::<model> = 165 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260823.4338665, \"EndTime\": 1635260824.3330154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1450.8626461029053, \"count\": 1, \"min\": 1450.8626461029053, \"max\": 1450.8626461029053}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:05 INFO 139626503206272] Epoch[0] Batch[0] avg_epoch_loss=8.132433\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:05 INFO 139626503206272] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=8.13243293762207\u001b[0m\n",
      "\n",
      "2021-10-26 15:07:13 Training - Training image download completed. Training in progress.\u001b[34m[10/26/2021 15:07:08 INFO 139626503206272] Epoch[0] Batch[5] avg_epoch_loss=7.392755\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=7.392754952112834\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:08 INFO 139626503206272] Epoch[0] Batch [5]#011Speed: 47.45 samples/sec#011loss=7.392755\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] Epoch[0] Batch[10] avg_epoch_loss=7.527087\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=7.688285827636719\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] Epoch[0] Batch [10]#011Speed: 56.86 samples/sec#011loss=7.688286\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] processed a total of 336 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260824.3332055, \"EndTime\": 1635260831.7465618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"update.time\": {\"sum\": 7413.239002227783, \"count\": 1, \"min\": 7413.239002227783, \"max\": 7413.239002227783}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=45.32330758490903 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=0, train loss <loss>=7.527087168260054\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:11 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_593a8677-eb49-4efd-94af-140b1f57c734-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260831.7466779, \"EndTime\": 1635260831.8425367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 95.16406059265137, \"count\": 1, \"min\": 95.16406059265137, \"max\": 95.16406059265137}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:12 INFO 139626503206272] Epoch[1] Batch[0] avg_epoch_loss=6.749702\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=6.749701976776123\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:15 INFO 139626503206272] Epoch[1] Batch[5] avg_epoch_loss=6.607282\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=6.607282400131226\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:15 INFO 139626503206272] Epoch[1] Batch [5]#011Speed: 60.81 samples/sec#011loss=6.607282\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] Epoch[1] Batch[10] avg_epoch_loss=6.644641\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=6.689471244812012\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] Epoch[1] Batch [10]#011Speed: 61.16 samples/sec#011loss=6.689471\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260831.842631, \"EndTime\": 1635260837.8702343, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6027.518749237061, \"count\": 1, \"min\": 6027.518749237061, \"max\": 6027.518749237061}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.75217353538815 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=1, train loss <loss>=6.64464096589522\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:17 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_4f71619f-65c1-43aa-87d6-9a3a925fad50-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260837.8703344, \"EndTime\": 1635260837.935524, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 64.61691856384277, \"count\": 1, \"min\": 64.61691856384277, \"max\": 64.61691856384277}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:18 INFO 139626503206272] Epoch[2] Batch[0] avg_epoch_loss=6.828318\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=6.828318119049072\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:21 INFO 139626503206272] Epoch[2] Batch[5] avg_epoch_loss=6.466193\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=6.466192722320557\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:21 INFO 139626503206272] Epoch[2] Batch [5]#011Speed: 61.91 samples/sec#011loss=6.466193\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260837.9356177, \"EndTime\": 1635260843.4145925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5478.8970947265625, \"count\": 1, \"min\": 5478.8970947265625, \"max\": 5478.8970947265625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.856693202706154 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=2, train loss <loss>=6.279587841033935\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:23 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_9e9992c2-b7bf-4352-8bf4-f80529bfa554-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260843.4147034, \"EndTime\": 1635260843.4897997, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 74.51748847961426, \"count\": 1, \"min\": 74.51748847961426, \"max\": 74.51748847961426}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:24 INFO 139626503206272] Epoch[3] Batch[0] avg_epoch_loss=6.934064\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=6.934063911437988\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:26 INFO 139626503206272] Epoch[3] Batch[5] avg_epoch_loss=6.385400\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=6.385400136311849\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:26 INFO 139626503206272] Epoch[3] Batch [5]#011Speed: 62.54 samples/sec#011loss=6.385400\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] processed a total of 309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260843.4898896, \"EndTime\": 1635260848.8701022, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5380.125284194946, \"count\": 1, \"min\": 5380.125284194946, \"max\": 5380.125284194946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.431362043373255 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=3, train loss <loss>=6.02449631690979\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:28 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_2ed32fda-bde3-44fb-8f4c-d1767ee6c887-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260848.8702083, \"EndTime\": 1635260848.9411385, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 70.23954391479492, \"count\": 1, \"min\": 70.23954391479492, \"max\": 70.23954391479492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:29 INFO 139626503206272] Epoch[4] Batch[0] avg_epoch_loss=6.350371\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=6.350371360778809\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:32 INFO 139626503206272] Epoch[4] Batch[5] avg_epoch_loss=5.927675\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=5.927675008773804\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:32 INFO 139626503206272] Epoch[4] Batch [5]#011Speed: 61.33 samples/sec#011loss=5.927675\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:34 INFO 139626503206272] processed a total of 309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260848.94123, \"EndTime\": 1635260854.3794525, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5438.138484954834, \"count\": 1, \"min\": 5438.138484954834, \"max\": 5438.138484954834}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:34 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.819275029434635 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:34 INFO 139626503206272] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=4, train loss <loss>=6.1107336521148685\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:34 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:35 INFO 139626503206272] Epoch[5] Batch[0] avg_epoch_loss=6.363751\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=6.36375093460083\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:37 INFO 139626503206272] Epoch[5] Batch[5] avg_epoch_loss=6.122741\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=6.122740825017293\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:37 INFO 139626503206272] Epoch[5] Batch [5]#011Speed: 62.87 samples/sec#011loss=6.122741\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] Epoch[5] Batch[10] avg_epoch_loss=6.192114\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=6.275361156463623\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] Epoch[5] Batch [10]#011Speed: 59.60 samples/sec#011loss=6.275361\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] processed a total of 339 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260854.3795624, \"EndTime\": 1635260860.3839455, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6003.836870193481, \"count\": 1, \"min\": 6003.836870193481, \"max\": 6003.836870193481}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.46261675674117 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=5, train loss <loss>=6.192113702947443\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:40 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:41 INFO 139626503206272] Epoch[6] Batch[0] avg_epoch_loss=6.662285\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=6.662285327911377\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:43 INFO 139626503206272] Epoch[6] Batch[5] avg_epoch_loss=5.971847\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=5.97184689839681\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:43 INFO 139626503206272] Epoch[6] Batch [5]#011Speed: 62.83 samples/sec#011loss=5.971847\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] Epoch[6] Batch[10] avg_epoch_loss=6.017306\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=6.071857070922851\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] Epoch[6] Batch [10]#011Speed: 62.42 samples/sec#011loss=6.071857\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260860.3840368, \"EndTime\": 1635260866.2973092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5912.785768508911, \"count\": 1, \"min\": 5912.785768508911, \"max\": 5912.785768508911}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.626114307898085 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=6, train loss <loss>=6.017306067726829\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:46 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_46f58f50-407c-402e-9b80-8ac63694942f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260866.297404, \"EndTime\": 1635260866.3725731, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 74.64098930358887, \"count\": 1, \"min\": 74.64098930358887, \"max\": 74.64098930358887}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:47 INFO 139626503206272] Epoch[7] Batch[0] avg_epoch_loss=5.645022\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=5.645022392272949\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:49 INFO 139626503206272] Epoch[7] Batch[5] avg_epoch_loss=5.365812\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=5.365812381108602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:49 INFO 139626503206272] Epoch[7] Batch [5]#011Speed: 62.96 samples/sec#011loss=5.365812\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] Epoch[7] Batch[10] avg_epoch_loss=5.514488\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=5.6928986549377445\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] Epoch[7] Batch [10]#011Speed: 62.61 samples/sec#011loss=5.692899\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] processed a total of 325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260866.3726585, \"EndTime\": 1635260872.2243373, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5851.6106605529785, \"count\": 1, \"min\": 5851.6106605529785, \"max\": 5851.6106605529785}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.53899210218255 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=7, train loss <loss>=5.514487960121849\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:52 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_d90dde25-0635-4a31-8792-f2204995c51a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260872.2244296, \"EndTime\": 1635260872.2853053, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 60.25362014770508, \"count\": 1, \"min\": 60.25362014770508, \"max\": 60.25362014770508}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:53 INFO 139626503206272] Epoch[8] Batch[0] avg_epoch_loss=6.472771\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=6.472771167755127\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:55 INFO 139626503206272] Epoch[8] Batch[5] avg_epoch_loss=5.980464\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=5.980464061101277\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:55 INFO 139626503206272] Epoch[8] Batch [5]#011Speed: 62.02 samples/sec#011loss=5.980464\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] Epoch[8] Batch[10] avg_epoch_loss=5.391038\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=4.6837256908416744\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] Epoch[8] Batch [10]#011Speed: 62.66 samples/sec#011loss=4.683726\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] processed a total of 329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260872.2854028, \"EndTime\": 1635260878.1641164, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5878.636121749878, \"count\": 1, \"min\": 5878.636121749878, \"max\": 5878.636121749878}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.964066223153345 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=8, train loss <loss>=5.391037529165095\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_eace73a8-1c3c-49ff-819f-c8ffb6d2e739-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260878.1642103, \"EndTime\": 1635260878.2352502, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 70.53565979003906, \"count\": 1, \"min\": 70.53565979003906, \"max\": 70.53565979003906}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] Epoch[9] Batch[0] avg_epoch_loss=5.630326\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:07:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=5.630326271057129\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:01 INFO 139626503206272] Epoch[9] Batch[5] avg_epoch_loss=5.376313\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=5.3763125737508135\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:01 INFO 139626503206272] Epoch[9] Batch [5]#011Speed: 61.11 samples/sec#011loss=5.376313\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:03 INFO 139626503206272] processed a total of 295 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260878.2353425, \"EndTime\": 1635260883.7886744, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5553.246021270752, \"count\": 1, \"min\": 5553.246021270752, \"max\": 5553.246021270752}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:03 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.12066287075845 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:03 INFO 139626503206272] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=9, train loss <loss>=5.398490953445434\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:03 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:04 INFO 139626503206272] Epoch[10] Batch[0] avg_epoch_loss=5.519816\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=5.519815921783447\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:07 INFO 139626503206272] Epoch[10] Batch[5] avg_epoch_loss=5.398293\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=5.3982930183410645\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:07 INFO 139626503206272] Epoch[10] Batch [5]#011Speed: 51.94 samples/sec#011loss=5.398293\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] Epoch[10] Batch[10] avg_epoch_loss=5.394728\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=5.390449953079224\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] Epoch[10] Batch [10]#011Speed: 62.37 samples/sec#011loss=5.390450\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260883.7887766, \"EndTime\": 1635260890.3889487, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6599.550724029541, \"count\": 1, \"min\": 6599.550724029541, \"max\": 6599.550724029541}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=49.09315675196747 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=10, train loss <loss>=5.394727988676592\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:10 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:11 INFO 139626503206272] Epoch[11] Batch[0] avg_epoch_loss=5.883167\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=5.883166790008545\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:13 INFO 139626503206272] Epoch[11] Batch[5] avg_epoch_loss=5.554518\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=5.554518222808838\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:13 INFO 139626503206272] Epoch[11] Batch [5]#011Speed: 63.17 samples/sec#011loss=5.554518\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:15 INFO 139626503206272] processed a total of 279 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260890.389033, \"EndTime\": 1635260895.319599, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4929.938316345215, \"count\": 1, \"min\": 4929.938316345215, \"max\": 4929.938316345215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:15 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.591300601824685 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:15 INFO 139626503206272] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=11, train loss <loss>=5.6878617604573565\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:15 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:16 INFO 139626503206272] Epoch[12] Batch[0] avg_epoch_loss=5.605623\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=5.6056227684021\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:18 INFO 139626503206272] Epoch[12] Batch[5] avg_epoch_loss=5.428527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=5.428526957829793\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:18 INFO 139626503206272] Epoch[12] Batch [5]#011Speed: 63.00 samples/sec#011loss=5.428527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] Epoch[12] Batch[10] avg_epoch_loss=5.558889\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=5.7153239250183105\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] Epoch[12] Batch [10]#011Speed: 61.86 samples/sec#011loss=5.715324\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] processed a total of 345 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260895.319701, \"EndTime\": 1635260901.1936076, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5873.359203338623, \"count\": 1, \"min\": 5873.359203338623, \"max\": 5873.359203338623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.73844550888228 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] #progress_metric: host=algo-1, completed 6.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=12, train loss <loss>=5.558889215642756\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:21 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:22 INFO 139626503206272] Epoch[13] Batch[0] avg_epoch_loss=5.745554\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=5.745553970336914\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:24 INFO 139626503206272] Epoch[13] Batch[5] avg_epoch_loss=5.818980\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=5.818980137507121\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:24 INFO 139626503206272] Epoch[13] Batch [5]#011Speed: 63.49 samples/sec#011loss=5.818980\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:26 INFO 139626503206272] processed a total of 314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260901.1936991, \"EndTime\": 1635260906.5966861, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5402.520179748535, \"count\": 1, \"min\": 5402.520179748535, \"max\": 5402.520179748535}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:26 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.11945080465172 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:26 INFO 139626503206272] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=13, train loss <loss>=5.663430023193359\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:26 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:27 INFO 139626503206272] Epoch[14] Batch[0] avg_epoch_loss=5.794564\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=5.794564247131348\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:29 INFO 139626503206272] Epoch[14] Batch[5] avg_epoch_loss=5.549875\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=5.549874862035115\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:29 INFO 139626503206272] Epoch[14] Batch [5]#011Speed: 61.55 samples/sec#011loss=5.549875\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] processed a total of 293 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260906.5967867, \"EndTime\": 1635260912.0368586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5439.499139785767, \"count\": 1, \"min\": 5439.499139785767, \"max\": 5439.499139785767}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.863782643546045 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] #progress_metric: host=algo-1, completed 7.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=14, train loss <loss>=5.976503705978393\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] Epoch[15] Batch[0] avg_epoch_loss=5.002392\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=5.002392292022705\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:35 INFO 139626503206272] Epoch[15] Batch[5] avg_epoch_loss=5.438100\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=5.438100020090739\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:35 INFO 139626503206272] Epoch[15] Batch [5]#011Speed: 62.41 samples/sec#011loss=5.438100\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] processed a total of 309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260912.0369613, \"EndTime\": 1635260917.4110203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5373.336553573608, \"count\": 1, \"min\": 5373.336553573608, \"max\": 5373.336553573608}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.50474781129298 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=15, train loss <loss>=5.3787493228912355\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:37 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_d5ab4a92-9e5c-464e-befd-4fcb8ce33e51-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260917.4111059, \"EndTime\": 1635260917.4778652, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 66.0552978515625, \"count\": 1, \"min\": 66.0552978515625, \"max\": 66.0552978515625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:38 INFO 139626503206272] Epoch[16] Batch[0] avg_epoch_loss=5.656986\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=5.656985759735107\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:40 INFO 139626503206272] Epoch[16] Batch[5] avg_epoch_loss=5.151102\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=5.151102224985759\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:40 INFO 139626503206272] Epoch[16] Batch [5]#011Speed: 62.68 samples/sec#011loss=5.151102\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] Epoch[16] Batch[10] avg_epoch_loss=5.536442\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=5.998848915100098\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] Epoch[16] Batch [10]#011Speed: 57.72 samples/sec#011loss=5.998849\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] processed a total of 330 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260917.477966, \"EndTime\": 1635260923.5465627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6068.510293960571, \"count\": 1, \"min\": 6068.510293960571, \"max\": 6068.510293960571}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.37782269145645 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] #progress_metric: host=algo-1, completed 8.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=16, train loss <loss>=5.5364416295831855\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:43 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:44 INFO 139626503206272] Epoch[17] Batch[0] avg_epoch_loss=5.788194\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=5.788193702697754\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:46 INFO 139626503206272] Epoch[17] Batch[5] avg_epoch_loss=5.635878\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=5.635877927144368\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:46 INFO 139626503206272] Epoch[17] Batch [5]#011Speed: 61.03 samples/sec#011loss=5.635878\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:48 INFO 139626503206272] processed a total of 301 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260923.5466568, \"EndTime\": 1635260928.9387546, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5391.503572463989, \"count\": 1, \"min\": 5391.503572463989, \"max\": 5391.503572463989}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:48 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.826957703640396 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:48 INFO 139626503206272] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=17, train loss <loss>=5.506862211227417\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:48 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:49 INFO 139626503206272] Epoch[18] Batch[0] avg_epoch_loss=5.336775\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=5.336775302886963\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:52 INFO 139626503206272] Epoch[18] Batch[5] avg_epoch_loss=5.340700\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=5.340699752171834\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:52 INFO 139626503206272] Epoch[18] Batch [5]#011Speed: 62.11 samples/sec#011loss=5.340700\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] processed a total of 314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260928.9388618, \"EndTime\": 1635260934.3332193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5393.81742477417, \"count\": 1, \"min\": 5393.81742477417, \"max\": 5393.81742477417}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.21306006819488 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] #progress_metric: host=algo-1, completed 9.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=18, train loss <loss>=5.258703231811523\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:54 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_47d93442-c69e-4626-bc5b-2003de321631-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260934.333332, \"EndTime\": 1635260934.4089904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 75.06155967712402, \"count\": 1, \"min\": 75.06155967712402, \"max\": 75.06155967712402}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:55 INFO 139626503206272] Epoch[19] Batch[0] avg_epoch_loss=5.000990\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=5.00098991394043\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:57 INFO 139626503206272] Epoch[19] Batch[5] avg_epoch_loss=4.932596\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=4.932595729827881\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:57 INFO 139626503206272] Epoch[19] Batch [5]#011Speed: 62.37 samples/sec#011loss=4.932596\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] processed a total of 303 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260934.4091024, \"EndTime\": 1635260939.7545614, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5345.377445220947, \"count\": 1, \"min\": 5345.377445220947, \"max\": 5345.377445220947}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.68290081244768 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=19, train loss <loss>=5.126478862762451\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:08:59 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_bd9f8d37-ed58-4a06-af9f-2dcd67ce09e5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260939.7546651, \"EndTime\": 1635260939.8342624, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 78.74798774719238, \"count\": 1, \"min\": 78.74798774719238, \"max\": 78.74798774719238}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:00 INFO 139626503206272] Epoch[20] Batch[0] avg_epoch_loss=4.868649\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=4.868649482727051\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:03 INFO 139626503206272] Epoch[20] Batch[5] avg_epoch_loss=5.140525\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=5.140525499979655\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:03 INFO 139626503206272] Epoch[20] Batch [5]#011Speed: 58.00 samples/sec#011loss=5.140525\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] Epoch[20] Batch[10] avg_epoch_loss=5.310902\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=5.515352725982666\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] Epoch[20] Batch [10]#011Speed: 50.07 samples/sec#011loss=5.515353\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] processed a total of 329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260939.834352, \"EndTime\": 1635260946.5712743, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6736.838579177856, \"count\": 1, \"min\": 6736.838579177856, \"max\": 6736.838579177856}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=48.8350436129168 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] #progress_metric: host=algo-1, completed 10.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=20, train loss <loss>=5.310901511799205\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:06 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:07 INFO 139626503206272] Epoch[21] Batch[0] avg_epoch_loss=5.868744\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=5.868743896484375\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:09 INFO 139626503206272] Epoch[21] Batch[5] avg_epoch_loss=5.823513\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=5.823513110478719\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:09 INFO 139626503206272] Epoch[21] Batch [5]#011Speed: 63.51 samples/sec#011loss=5.823513\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] Epoch[21] Batch[10] avg_epoch_loss=5.501206\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=5.114436912536621\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] Epoch[21] Batch [10]#011Speed: 57.82 samples/sec#011loss=5.114437\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] processed a total of 322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260946.571356, \"EndTime\": 1635260952.7009819, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6129.106760025024, \"count\": 1, \"min\": 6129.106760025024, \"max\": 6129.106760025024}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=52.534807737040815 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=21, train loss <loss>=5.501205747777766\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:12 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:13 INFO 139626503206272] Epoch[22] Batch[0] avg_epoch_loss=5.174511\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=5.174510955810547\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:16 INFO 139626503206272] Epoch[22] Batch[5] avg_epoch_loss=5.190473\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=5.190472682317098\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:16 INFO 139626503206272] Epoch[22] Batch [5]#011Speed: 62.98 samples/sec#011loss=5.190473\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] Epoch[22] Batch[10] avg_epoch_loss=5.250108\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=5.321670436859131\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] Epoch[22] Batch [10]#011Speed: 60.89 samples/sec#011loss=5.321670\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] processed a total of 328 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260952.7010992, \"EndTime\": 1635260958.6826692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5981.065511703491, \"count\": 1, \"min\": 5981.065511703491, \"max\": 5981.065511703491}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.83840013801563 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] #progress_metric: host=algo-1, completed 11.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=22, train loss <loss>=5.250108025290749\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:18 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:19 INFO 139626503206272] Epoch[23] Batch[0] avg_epoch_loss=6.413522\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=6.413521766662598\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:22 INFO 139626503206272] Epoch[23] Batch[5] avg_epoch_loss=5.634545\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=5.634544928868611\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:22 INFO 139626503206272] Epoch[23] Batch [5]#011Speed: 61.10 samples/sec#011loss=5.634545\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] processed a total of 303 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260958.682768, \"EndTime\": 1635260964.1272285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5443.605184555054, \"count\": 1, \"min\": 5443.605184555054, \"max\": 5443.605184555054}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.6601202684266 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=23, train loss <loss>=5.507904577255249\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] Epoch[24] Batch[0] avg_epoch_loss=5.695982\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=5.695982456207275\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:27 INFO 139626503206272] Epoch[24] Batch[5] avg_epoch_loss=5.239331\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=5.239331483840942\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:27 INFO 139626503206272] Epoch[24] Batch [5]#011Speed: 62.10 samples/sec#011loss=5.239331\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:29 INFO 139626503206272] processed a total of 303 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260964.1273305, \"EndTime\": 1635260969.5489202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5421.002626419067, \"count\": 1, \"min\": 5421.002626419067, \"max\": 5421.002626419067}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:29 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.89220522924033 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:29 INFO 139626503206272] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=24, train loss <loss>=5.446295642852784\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:29 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:30 INFO 139626503206272] Epoch[25] Batch[0] avg_epoch_loss=5.690405\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=5.690405368804932\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:32 INFO 139626503206272] Epoch[25] Batch[5] avg_epoch_loss=5.636228\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=5.6362284024556475\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:32 INFO 139626503206272] Epoch[25] Batch [5]#011Speed: 61.39 samples/sec#011loss=5.636228\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:34 INFO 139626503206272] processed a total of 314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260969.54902, \"EndTime\": 1635260974.955255, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5405.608654022217, \"count\": 1, \"min\": 5405.608654022217, \"max\": 5405.608654022217}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:34 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.08624537171985 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:34 INFO 139626503206272] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=25, train loss <loss>=5.659997272491455\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:34 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:35 INFO 139626503206272] Epoch[26] Batch[0] avg_epoch_loss=5.391334\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=5.39133358001709\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:38 INFO 139626503206272] Epoch[26] Batch[5] avg_epoch_loss=5.392891\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=5.39289132754008\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:38 INFO 139626503206272] Epoch[26] Batch [5]#011Speed: 61.40 samples/sec#011loss=5.392891\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] Epoch[26] Batch[10] avg_epoch_loss=5.455534\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=5.53070478439331\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] Epoch[26] Batch [10]#011Speed: 62.78 samples/sec#011loss=5.530705\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260974.9553545, \"EndTime\": 1635260980.8464537, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5890.446186065674, \"count\": 1, \"min\": 5890.446186065674, \"max\": 5890.446186065674}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.512394691225126 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] #progress_metric: host=algo-1, completed 13.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=26, train loss <loss>=5.455533807927912\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:40 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:41 INFO 139626503206272] Epoch[27] Batch[0] avg_epoch_loss=5.592218\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=5.592217922210693\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:44 INFO 139626503206272] Epoch[27] Batch[5] avg_epoch_loss=5.879201\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=5.8792009353637695\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:44 INFO 139626503206272] Epoch[27] Batch [5]#011Speed: 57.51 samples/sec#011loss=5.879201\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] Epoch[27] Batch[10] avg_epoch_loss=6.028626\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=6.20793571472168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] Epoch[27] Batch [10]#011Speed: 62.47 samples/sec#011loss=6.207936\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260980.8465433, \"EndTime\": 1635260986.9848676, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6137.754201889038, \"count\": 1, \"min\": 6137.754201889038, \"max\": 6137.754201889038}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=52.623893309107295 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] #progress_metric: host=algo-1, completed 14.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=27, train loss <loss>=6.02862583507191\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:46 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:47 INFO 139626503206272] Epoch[28] Batch[0] avg_epoch_loss=5.708393\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=5.708393096923828\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:50 INFO 139626503206272] Epoch[28] Batch[5] avg_epoch_loss=5.524230\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=5.5242297649383545\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:50 INFO 139626503206272] Epoch[28] Batch [5]#011Speed: 63.41 samples/sec#011loss=5.524230\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] processed a total of 291 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260986.9849644, \"EndTime\": 1635260992.3610122, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5375.529766082764, \"count\": 1, \"min\": 5375.529766082764, \"max\": 5375.529766082764}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.13106144236054 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] #progress_metric: host=algo-1, completed 14.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=28, train loss <loss>=4.871221667528152\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:52 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_0f7f2e08-61bf-4842-968a-34dfc6219f61-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260992.3611162, \"EndTime\": 1635260992.4221983, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 60.27054786682129, \"count\": 1, \"min\": 60.27054786682129, \"max\": 60.27054786682129}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:53 INFO 139626503206272] Epoch[29] Batch[0] avg_epoch_loss=6.177737\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=6.177737236022949\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:55 INFO 139626503206272] Epoch[29] Batch[5] avg_epoch_loss=5.773106\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=5.77310570081075\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:55 INFO 139626503206272] Epoch[29] Batch [5]#011Speed: 63.54 samples/sec#011loss=5.773106\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] Epoch[29] Batch[10] avg_epoch_loss=5.964226\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=6.1935700416564945\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] Epoch[29] Batch [10]#011Speed: 62.10 samples/sec#011loss=6.193570\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] processed a total of 328 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260992.4222972, \"EndTime\": 1635260998.2638888, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5841.485500335693, \"count\": 1, \"min\": 5841.485500335693, \"max\": 5841.485500335693}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.148599800805016 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=29, train loss <loss>=5.964225855740634\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:58 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:59 INFO 139626503206272] Epoch[30] Batch[0] avg_epoch_loss=5.528841\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:09:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=5.528841018676758\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:01 INFO 139626503206272] Epoch[30] Batch[5] avg_epoch_loss=5.924868\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=5.924867630004883\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:01 INFO 139626503206272] Epoch[30] Batch [5]#011Speed: 62.63 samples/sec#011loss=5.924868\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:03 INFO 139626503206272] processed a total of 305 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635260998.263977, \"EndTime\": 1635261003.8495352, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5584.901571273804, \"count\": 1, \"min\": 5584.901571273804, \"max\": 5584.901571273804}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:03 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.61028621738021 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:03 INFO 139626503206272] #progress_metric: host=algo-1, completed 15.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=30, train loss <loss>=6.044228219985962\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:03 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:04 INFO 139626503206272] Epoch[31] Batch[0] avg_epoch_loss=5.963077\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=5.963077068328857\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:08 INFO 139626503206272] Epoch[31] Batch[5] avg_epoch_loss=5.533633\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=5.533632755279541\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:08 INFO 139626503206272] Epoch[31] Batch [5]#011Speed: 49.70 samples/sec#011loss=5.533633\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] processed a total of 297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261003.8496208, \"EndTime\": 1635261010.030213, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6179.75378036499, \"count\": 1, \"min\": 6179.75378036499, \"max\": 6179.75378036499}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=48.05902691013685 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 16.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=31, train loss <loss>=5.800917863845825\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] Epoch[32] Batch[0] avg_epoch_loss=5.302721\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=5.30272102355957\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:13 INFO 139626503206272] Epoch[32] Batch[5] avg_epoch_loss=5.459328\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=5.459328254063924\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:13 INFO 139626503206272] Epoch[32] Batch [5]#011Speed: 59.03 samples/sec#011loss=5.459328\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:15 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261010.0303142, \"EndTime\": 1635261015.5357985, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5504.876136779785, \"count\": 1, \"min\": 5504.876136779785, \"max\": 5504.876136779785}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:15 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.58366668062666 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:15 INFO 139626503206272] #progress_metric: host=algo-1, completed 16.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=32, train loss <loss>=5.561108589172363\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:15 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:16 INFO 139626503206272] Epoch[33] Batch[0] avg_epoch_loss=5.577822\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=5.577821731567383\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:18 INFO 139626503206272] Epoch[33] Batch[5] avg_epoch_loss=5.606527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=5.60652740796407\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:18 INFO 139626503206272] Epoch[33] Batch [5]#011Speed: 62.38 samples/sec#011loss=5.606527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] Epoch[33] Batch[10] avg_epoch_loss=5.066369\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=4.41817809343338\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] Epoch[33] Batch [10]#011Speed: 62.74 samples/sec#011loss=4.418178\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261015.5359092, \"EndTime\": 1635261021.420065, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5883.614778518677, \"count\": 1, \"min\": 5883.614778518677, \"max\": 5883.614778518677}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.06687287246936 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] #progress_metric: host=algo-1, completed 17.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=33, train loss <loss>=5.066368628631938\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:21 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:22 INFO 139626503206272] Epoch[34] Batch[0] avg_epoch_loss=5.159016\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=5.159016132354736\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:24 INFO 139626503206272] Epoch[34] Batch[5] avg_epoch_loss=5.539286\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=5.539285818735759\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:24 INFO 139626503206272] Epoch[34] Batch [5]#011Speed: 62.85 samples/sec#011loss=5.539286\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] Epoch[34] Batch[10] avg_epoch_loss=5.442002\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=5.325261068344116\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] Epoch[34] Batch [10]#011Speed: 62.55 samples/sec#011loss=5.325261\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261021.4201615, \"EndTime\": 1635261027.3606105, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5939.849376678467, \"count\": 1, \"min\": 5939.849376678467, \"max\": 5939.849376678467}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.04932019656506 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] #progress_metric: host=algo-1, completed 17.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=34, train loss <loss>=5.442001841285012\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:27 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:28 INFO 139626503206272] Epoch[35] Batch[0] avg_epoch_loss=5.267847\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=5.267847061157227\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:30 INFO 139626503206272] Epoch[35] Batch[5] avg_epoch_loss=5.531522\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=5.5315219561258955\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:30 INFO 139626503206272] Epoch[35] Batch [5]#011Speed: 63.12 samples/sec#011loss=5.531522\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:32 INFO 139626503206272] processed a total of 313 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261027.3608506, \"EndTime\": 1635261032.7738476, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5412.13846206665, \"count\": 1, \"min\": 5412.13846206665, \"max\": 5412.13846206665}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:32 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.83151276723653 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:32 INFO 139626503206272] #progress_metric: host=algo-1, completed 18.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=35, train loss <loss>=5.526813745498657\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:32 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:33 INFO 139626503206272] Epoch[36] Batch[0] avg_epoch_loss=5.708258\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=5.708258152008057\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:36 INFO 139626503206272] Epoch[36] Batch[5] avg_epoch_loss=5.028656\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=5.028656085332234\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:36 INFO 139626503206272] Epoch[36] Batch [5]#011Speed: 62.89 samples/sec#011loss=5.028656\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] processed a total of 298 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261032.773923, \"EndTime\": 1635261038.1425602, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5368.094444274902, \"count\": 1, \"min\": 5368.094444274902, \"max\": 5368.094444274902}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.51061721069831 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] #progress_metric: host=algo-1, completed 18.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=36, train loss <loss>=5.332891130447388\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] Epoch[37] Batch[0] avg_epoch_loss=5.497173\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=5.497172832489014\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:41 INFO 139626503206272] Epoch[37] Batch[5] avg_epoch_loss=5.334102\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=5.334101915359497\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:41 INFO 139626503206272] Epoch[37] Batch [5]#011Speed: 63.44 samples/sec#011loss=5.334102\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] Epoch[37] Batch[10] avg_epoch_loss=5.500723\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=5.700667381286621\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] Epoch[37] Batch [10]#011Speed: 58.33 samples/sec#011loss=5.700667\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] processed a total of 341 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261038.14276, \"EndTime\": 1635261044.153917, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6010.592222213745, \"count\": 1, \"min\": 6010.592222213745, \"max\": 6010.592222213745}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.73039465183491 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] #progress_metric: host=algo-1, completed 19.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=37, train loss <loss>=5.500722581690008\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] Epoch[38] Batch[0] avg_epoch_loss=5.414052\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=5.4140520095825195\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:47 INFO 139626503206272] Epoch[38] Batch[5] avg_epoch_loss=5.371823\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=5.3718234697977705\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:47 INFO 139626503206272] Epoch[38] Batch [5]#011Speed: 63.23 samples/sec#011loss=5.371823\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] Epoch[38] Batch[10] avg_epoch_loss=5.173527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=4.935571479797363\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] Epoch[38] Batch [10]#011Speed: 61.38 samples/sec#011loss=4.935571\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] processed a total of 337 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261044.1540263, \"EndTime\": 1635261050.0207078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5865.916013717651, \"count\": 1, \"min\": 5865.916013717651, \"max\": 5865.916013717651}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.44883753605742 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] #progress_metric: host=algo-1, completed 19.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=38, train loss <loss>=5.173527110706676\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] Epoch[39] Batch[0] avg_epoch_loss=4.938067\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=4.9380669593811035\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:53 INFO 139626503206272] Epoch[39] Batch[5] avg_epoch_loss=5.325041\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=5.325040817260742\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:53 INFO 139626503206272] Epoch[39] Batch [5]#011Speed: 61.73 samples/sec#011loss=5.325041\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] Epoch[39] Batch[10] avg_epoch_loss=5.160105\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=4.962182426452637\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] Epoch[39] Batch [10]#011Speed: 63.25 samples/sec#011loss=4.962182\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261050.0208046, \"EndTime\": 1635261055.9086204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5887.269973754883, \"count\": 1, \"min\": 5887.269973754883, \"max\": 5887.269973754883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.03268686591839 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=39, train loss <loss>=5.160105185075239\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:55 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:56 INFO 139626503206272] Epoch[40] Batch[0] avg_epoch_loss=4.864660\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=4.864660263061523\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:59 INFO 139626503206272] Epoch[40] Batch[5] avg_epoch_loss=5.447165\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=5.447165250778198\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:10:59 INFO 139626503206272] Epoch[40] Batch [5]#011Speed: 63.37 samples/sec#011loss=5.447165\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:01 INFO 139626503206272] processed a total of 298 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261055.9087174, \"EndTime\": 1635261061.3559086, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5446.5954303741455, \"count\": 1, \"min\": 5446.5954303741455, \"max\": 5446.5954303741455}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:01 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.711128423547564 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:01 INFO 139626503206272] #progress_metric: host=algo-1, completed 20.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=40, train loss <loss>=5.270882511138916\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:01 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:02 INFO 139626503206272] Epoch[41] Batch[0] avg_epoch_loss=5.520474\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=5.520473957061768\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:04 INFO 139626503206272] Epoch[41] Batch[5] avg_epoch_loss=5.025615\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=5.025614658991496\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:04 INFO 139626503206272] Epoch[41] Batch [5]#011Speed: 58.66 samples/sec#011loss=5.025615\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:06 INFO 139626503206272] processed a total of 285 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261061.356052, \"EndTime\": 1635261066.9674304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5610.130310058594, \"count\": 1, \"min\": 5610.130310058594, \"max\": 5610.130310058594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:06 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=50.79959029759011 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:06 INFO 139626503206272] #progress_metric: host=algo-1, completed 21.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=41, train loss <loss>=5.1694153679741754\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:06 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:07 INFO 139626503206272] Epoch[42] Batch[0] avg_epoch_loss=5.021224\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=5.021224498748779\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:10 INFO 139626503206272] Epoch[42] Batch[5] avg_epoch_loss=5.030883\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=5.030882914861043\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:10 INFO 139626503206272] Epoch[42] Batch [5]#011Speed: 63.46 samples/sec#011loss=5.030883\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] Epoch[42] Batch[10] avg_epoch_loss=5.066334\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=5.108875274658203\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] Epoch[42] Batch [10]#011Speed: 62.57 samples/sec#011loss=5.108875\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] processed a total of 337 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261066.9675345, \"EndTime\": 1635261072.8447285, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5876.63722038269, \"count\": 1, \"min\": 5876.63722038269, \"max\": 5876.63722038269}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.344374222026694 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] #progress_metric: host=algo-1, completed 21.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=42, train loss <loss>=5.066333987496116\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:12 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:13 INFO 139626503206272] Epoch[43] Batch[0] avg_epoch_loss=5.199800\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=5.19980001449585\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:16 INFO 139626503206272] Epoch[43] Batch[5] avg_epoch_loss=5.419142\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=5.419142325719197\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:16 INFO 139626503206272] Epoch[43] Batch [5]#011Speed: 59.06 samples/sec#011loss=5.419142\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:18 INFO 139626503206272] processed a total of 297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261072.8448243, \"EndTime\": 1635261078.3673844, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5521.934032440186, \"count\": 1, \"min\": 5521.934032440186, \"max\": 5521.934032440186}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:18 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.783197173708984 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:18 INFO 139626503206272] #progress_metric: host=algo-1, completed 22.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=43, train loss <loss>=5.537340497970581\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:18 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:19 INFO 139626503206272] Epoch[44] Batch[0] avg_epoch_loss=5.357822\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=5.357821941375732\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:21 INFO 139626503206272] Epoch[44] Batch[5] avg_epoch_loss=4.927399\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=4.927399158477783\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:21 INFO 139626503206272] Epoch[44] Batch [5]#011Speed: 63.59 samples/sec#011loss=4.927399\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:23 INFO 139626503206272] processed a total of 301 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261078.3675468, \"EndTime\": 1635261083.6587133, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5290.497303009033, \"count\": 1, \"min\": 5290.497303009033, \"max\": 5290.497303009033}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:23 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.89281127079135 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:23 INFO 139626503206272] #progress_metric: host=algo-1, completed 22.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=44, train loss <loss>=4.983349800109863\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:23 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:24 INFO 139626503206272] Epoch[45] Batch[0] avg_epoch_loss=5.670942\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=5.6709418296813965\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:26 INFO 139626503206272] Epoch[45] Batch[5] avg_epoch_loss=5.577653\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=5.5776534875233965\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:26 INFO 139626503206272] Epoch[45] Batch [5]#011Speed: 62.90 samples/sec#011loss=5.577653\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] Epoch[45] Batch[10] avg_epoch_loss=5.360680\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=5.10031099319458\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] Epoch[45] Batch [10]#011Speed: 62.59 samples/sec#011loss=5.100311\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] processed a total of 342 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261083.6588175, \"EndTime\": 1635261089.5474713, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5888.074636459351, \"count\": 1, \"min\": 5888.074636459351, \"max\": 5888.074636459351}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.082030607683905 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] #progress_metric: host=algo-1, completed 23.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=45, train loss <loss>=5.360679626464844\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:29 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:30 INFO 139626503206272] Epoch[46] Batch[0] avg_epoch_loss=4.753382\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=4.753381729125977\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:32 INFO 139626503206272] Epoch[46] Batch[5] avg_epoch_loss=5.144010\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=5.144010146458943\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:32 INFO 139626503206272] Epoch[46] Batch [5]#011Speed: 63.33 samples/sec#011loss=5.144010\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] Epoch[46] Batch[10] avg_epoch_loss=4.953775\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=4.72549352645874\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] Epoch[46] Batch [10]#011Speed: 62.74 samples/sec#011loss=4.725494\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] processed a total of 333 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261089.5475755, \"EndTime\": 1635261095.3783374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5830.167293548584, \"count\": 1, \"min\": 5830.167293548584, \"max\": 5830.167293548584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.115233550752656 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] #progress_metric: host=algo-1, completed 23.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=46, train loss <loss>=4.953775319186124\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:35 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:36 INFO 139626503206272] Epoch[47] Batch[0] avg_epoch_loss=5.072869\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=5.072868824005127\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:38 INFO 139626503206272] Epoch[47] Batch[5] avg_epoch_loss=5.688053\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=5.688052654266357\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:38 INFO 139626503206272] Epoch[47] Batch [5]#011Speed: 63.00 samples/sec#011loss=5.688053\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] Epoch[47] Batch[10] avg_epoch_loss=5.536769\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=5.355227851867676\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] Epoch[47] Batch [10]#011Speed: 62.53 samples/sec#011loss=5.355228\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] processed a total of 348 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261095.3784397, \"EndTime\": 1635261101.2147465, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5835.61635017395, \"count\": 1, \"min\": 5835.61635017395, \"max\": 5835.61635017395}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=59.63233461421177 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] #progress_metric: host=algo-1, completed 24.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=47, train loss <loss>=5.536768653176048\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] Epoch[48] Batch[0] avg_epoch_loss=5.398434\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=5.398434162139893\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:44 INFO 139626503206272] Epoch[48] Batch[5] avg_epoch_loss=5.568297\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=5.568296670913696\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:44 INFO 139626503206272] Epoch[48] Batch [5]#011Speed: 61.23 samples/sec#011loss=5.568297\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] processed a total of 287 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261101.2148466, \"EndTime\": 1635261106.1864421, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4971.106052398682, \"count\": 1, \"min\": 4971.106052398682, \"max\": 4971.106052398682}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.73188887858827 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] #progress_metric: host=algo-1, completed 24.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=48, train loss <loss>=5.4783741103278265\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] Epoch[49] Batch[0] avg_epoch_loss=4.983238\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=4.9832377433776855\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:49 INFO 139626503206272] Epoch[49] Batch[5] avg_epoch_loss=5.113949\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=5.113948901494344\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:49 INFO 139626503206272] Epoch[49] Batch [5]#011Speed: 63.16 samples/sec#011loss=5.113949\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:51 INFO 139626503206272] processed a total of 310 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261106.186545, \"EndTime\": 1635261111.5449848, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5357.855319976807, \"count\": 1, \"min\": 5357.855319976807, \"max\": 5357.855319976807}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:51 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.857136150738214 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:51 INFO 139626503206272] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=49, train loss <loss>=5.151808786392212\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:51 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:52 INFO 139626503206272] Epoch[50] Batch[0] avg_epoch_loss=5.194668\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=5.194667816162109\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:54 INFO 139626503206272] Epoch[50] Batch[5] avg_epoch_loss=5.266168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=5.266167561213176\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:54 INFO 139626503206272] Epoch[50] Batch [5]#011Speed: 63.33 samples/sec#011loss=5.266168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:56 INFO 139626503206272] processed a total of 281 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261111.5451088, \"EndTime\": 1635261116.3641224, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4818.415403366089, \"count\": 1, \"min\": 4818.415403366089, \"max\": 4818.415403366089}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:56 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.31625674563462 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:56 INFO 139626503206272] #progress_metric: host=algo-1, completed 25.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=50, train loss <loss>=5.128044234381782\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:56 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:57 INFO 139626503206272] Epoch[51] Batch[0] avg_epoch_loss=5.215886\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=5.215886116027832\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:59 INFO 139626503206272] Epoch[51] Batch[5] avg_epoch_loss=4.950055\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=4.95005464553833\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:11:59 INFO 139626503206272] Epoch[51] Batch [5]#011Speed: 62.12 samples/sec#011loss=4.950055\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] Epoch[51] Batch[10] avg_epoch_loss=4.877650\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=4.790764045715332\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] Epoch[51] Batch [10]#011Speed: 59.58 samples/sec#011loss=4.790764\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] processed a total of 335 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261116.3642101, \"EndTime\": 1635261122.3655088, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6000.478029251099, \"count\": 1, \"min\": 6000.478029251099, \"max\": 6000.478029251099}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.827339272868024 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] #progress_metric: host=algo-1, completed 26.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=51, train loss <loss>=4.877649827436968\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:02 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:03 INFO 139626503206272] Epoch[52] Batch[0] avg_epoch_loss=6.385440\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=6.385439872741699\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:05 INFO 139626503206272] Epoch[52] Batch[5] avg_epoch_loss=5.332422\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:05 INFO 139626503206272] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=5.332421779632568\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:05 INFO 139626503206272] Epoch[52] Batch [5]#011Speed: 57.19 samples/sec#011loss=5.332422\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:08 INFO 139626503206272] processed a total of 314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261122.3656228, \"EndTime\": 1635261128.6226265, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6256.286859512329, \"count\": 1, \"min\": 6256.286859512329, \"max\": 6256.286859512329}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:08 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=50.18781419984972 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:08 INFO 139626503206272] #progress_metric: host=algo-1, completed 26.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=52, train loss <loss>=5.289991664886474\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:08 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:09 INFO 139626503206272] Epoch[53] Batch[0] avg_epoch_loss=4.672657\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=4.672656536102295\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:11 INFO 139626503206272] Epoch[53] Batch[5] avg_epoch_loss=4.951581\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=4.951581239700317\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:11 INFO 139626503206272] Epoch[53] Batch [5]#011Speed: 63.04 samples/sec#011loss=4.951581\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] Epoch[53] Batch[10] avg_epoch_loss=5.022017\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=5.106539726257324\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] Epoch[53] Batch [10]#011Speed: 62.04 samples/sec#011loss=5.106540\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] processed a total of 322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261128.6227095, \"EndTime\": 1635261134.4837272, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5860.185146331787, \"count\": 1, \"min\": 5860.185146331787, \"max\": 5860.185146331787}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.945652145611525 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] #progress_metric: host=algo-1, completed 27.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=53, train loss <loss>=5.022016915408048\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:14 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:15 INFO 139626503206272] Epoch[54] Batch[0] avg_epoch_loss=5.696922\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=5.6969218254089355\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:17 INFO 139626503206272] Epoch[54] Batch[5] avg_epoch_loss=5.328410\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=5.328409592310588\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:17 INFO 139626503206272] Epoch[54] Batch [5]#011Speed: 62.33 samples/sec#011loss=5.328410\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] Epoch[54] Batch[10] avg_epoch_loss=5.476596\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=5.654419994354248\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] Epoch[54] Batch [10]#011Speed: 61.66 samples/sec#011loss=5.654420\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] processed a total of 336 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261134.48383, \"EndTime\": 1635261140.5327835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6048.379182815552, \"count\": 1, \"min\": 6048.379182815552, \"max\": 6048.379182815552}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.55078074388324 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] #progress_metric: host=algo-1, completed 27.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=54, train loss <loss>=5.476596138694069\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:20 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:21 INFO 139626503206272] Epoch[55] Batch[0] avg_epoch_loss=5.037635\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=5.037635326385498\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:23 INFO 139626503206272] Epoch[55] Batch[5] avg_epoch_loss=5.075588\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=5.075587670008342\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:23 INFO 139626503206272] Epoch[55] Batch [5]#011Speed: 61.97 samples/sec#011loss=5.075588\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:25 INFO 139626503206272] processed a total of 315 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261140.5328805, \"EndTime\": 1635261145.9447553, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5411.279916763306, \"count\": 1, \"min\": 5411.279916763306, \"max\": 5411.279916763306}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:25 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.20980772827435 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:25 INFO 139626503206272] #progress_metric: host=algo-1, completed 28.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=55, train loss <loss>=5.043646144866943\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:25 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:26 INFO 139626503206272] Epoch[56] Batch[0] avg_epoch_loss=4.975670\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=4.975670337677002\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:29 INFO 139626503206272] Epoch[56] Batch[5] avg_epoch_loss=5.152806\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=5.15280556678772\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:29 INFO 139626503206272] Epoch[56] Batch [5]#011Speed: 62.32 samples/sec#011loss=5.152806\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:30 INFO 139626503206272] processed a total of 279 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261145.9448862, \"EndTime\": 1635261150.843095, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4897.539377212524, \"count\": 1, \"min\": 4897.539377212524, \"max\": 4897.539377212524}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:30 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.96552746076196 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:30 INFO 139626503206272] #progress_metric: host=algo-1, completed 28.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=56, train loss <loss>=5.24188052283393\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:30 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:31 INFO 139626503206272] Epoch[57] Batch[0] avg_epoch_loss=5.800314\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=5.800314426422119\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:34 INFO 139626503206272] Epoch[57] Batch[5] avg_epoch_loss=5.078096\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=5.078095515569051\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:34 INFO 139626503206272] Epoch[57] Batch [5]#011Speed: 60.83 samples/sec#011loss=5.078096\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:36 INFO 139626503206272] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261150.843206, \"EndTime\": 1635261156.3179486, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5474.208831787109, \"count\": 1, \"min\": 5474.208831787109, \"max\": 5474.208831787109}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:36 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.45439554488262 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:36 INFO 139626503206272] #progress_metric: host=algo-1, completed 29.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=57, train loss <loss>=4.962270450592041\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:36 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:37 INFO 139626503206272] Epoch[58] Batch[0] avg_epoch_loss=4.784352\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=4.7843523025512695\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:39 INFO 139626503206272] Epoch[58] Batch[5] avg_epoch_loss=5.125468\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=5.125467856725057\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:39 INFO 139626503206272] Epoch[58] Batch [5]#011Speed: 60.89 samples/sec#011loss=5.125468\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:41 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261156.3180478, \"EndTime\": 1635261161.79557, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5476.97639465332, \"count\": 1, \"min\": 5476.97639465332, \"max\": 5476.97639465332}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:41 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.87705018543936 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:41 INFO 139626503206272] #progress_metric: host=algo-1, completed 29.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=58, train loss <loss>=4.989803171157837\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:41 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:42 INFO 139626503206272] Epoch[59] Batch[0] avg_epoch_loss=5.632623\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=5.632623195648193\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:45 INFO 139626503206272] Epoch[59] Batch[5] avg_epoch_loss=5.112363\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:45 INFO 139626503206272] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=5.1123632589976\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:45 INFO 139626503206272] Epoch[59] Batch [5]#011Speed: 62.23 samples/sec#011loss=5.112363\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] processed a total of 292 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261161.7956743, \"EndTime\": 1635261167.3106375, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5514.409065246582, \"count\": 1, \"min\": 5514.409065246582, \"max\": 5514.409065246582}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=52.95077083709383 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=59, train loss <loss>=4.837201738357544\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:47 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_42264299-144a-4923-ac8e-05638430d81f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261167.310739, \"EndTime\": 1635261167.3764374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 65.12665748596191, \"count\": 1, \"min\": 65.12665748596191, \"max\": 65.12665748596191}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:48 INFO 139626503206272] Epoch[60] Batch[0] avg_epoch_loss=5.152104\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=5.152103900909424\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:50 INFO 139626503206272] Epoch[60] Batch[5] avg_epoch_loss=5.109600\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=5.109599749247233\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:50 INFO 139626503206272] Epoch[60] Batch [5]#011Speed: 62.54 samples/sec#011loss=5.109600\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:52 INFO 139626503206272] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261167.3765275, \"EndTime\": 1635261172.7118158, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5335.203409194946, \"count\": 1, \"min\": 5335.203409194946, \"max\": 5335.203409194946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:52 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=59.977272420560496 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:52 INFO 139626503206272] #progress_metric: host=algo-1, completed 30.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=60, train loss <loss>=5.133485984802246\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:52 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:53 INFO 139626503206272] Epoch[61] Batch[0] avg_epoch_loss=5.446915\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=5.446915149688721\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:56 INFO 139626503206272] Epoch[61] Batch[5] avg_epoch_loss=5.089403\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=5.089403470357259\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:56 INFO 139626503206272] Epoch[61] Batch [5]#011Speed: 62.43 samples/sec#011loss=5.089403\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] processed a total of 310 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261172.7119205, \"EndTime\": 1635261178.1350155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5422.529935836792, \"count\": 1, \"min\": 5422.529935836792, \"max\": 5422.529935836792}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.16697902059654 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] #progress_metric: host=algo-1, completed 31.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=61, train loss <loss>=5.021593618392944\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] Epoch[62] Batch[0] avg_epoch_loss=5.223424\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:12:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=5.223424434661865\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:01 INFO 139626503206272] Epoch[62] Batch[5] avg_epoch_loss=5.079217\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=5.079217116038005\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:01 INFO 139626503206272] Epoch[62] Batch [5]#011Speed: 61.40 samples/sec#011loss=5.079217\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] Epoch[62] Batch[10] avg_epoch_loss=5.037587\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=4.9876314163208\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] Epoch[62] Batch [10]#011Speed: 58.11 samples/sec#011loss=4.987631\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261178.135129, \"EndTime\": 1635261184.3145077, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6178.5829067230225, \"count\": 1, \"min\": 6178.5829067230225, \"max\": 6178.5829067230225}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=52.923564520747654 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] #progress_metric: host=algo-1, completed 31.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=62, train loss <loss>=5.037587252530185\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:04 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:05 INFO 139626503206272] Epoch[63] Batch[0] avg_epoch_loss=4.663804\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:05 INFO 139626503206272] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=4.663803577423096\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:08 INFO 139626503206272] Epoch[63] Batch[5] avg_epoch_loss=4.943340\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=4.943339665730794\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:08 INFO 139626503206272] Epoch[63] Batch [5]#011Speed: 51.69 samples/sec#011loss=4.943340\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] Epoch[63] Batch[10] avg_epoch_loss=4.940215\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=4.936466026306152\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] Epoch[63] Batch [10]#011Speed: 61.97 samples/sec#011loss=4.936466\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] processed a total of 343 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261184.3146036, \"EndTime\": 1635261190.983192, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6667.975425720215, \"count\": 1, \"min\": 6667.975425720215, \"max\": 6667.975425720215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=51.438021965967614 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 32.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=63, train loss <loss>=4.940215284174139\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:10 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:11 INFO 139626503206272] Epoch[64] Batch[0] avg_epoch_loss=5.304484\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=5.3044843673706055\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:14 INFO 139626503206272] Epoch[64] Batch[5] avg_epoch_loss=5.022490\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=5.022489547729492\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:14 INFO 139626503206272] Epoch[64] Batch [5]#011Speed: 62.81 samples/sec#011loss=5.022490\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] Epoch[64] Batch[10] avg_epoch_loss=5.086674\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=5.163695049285889\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] Epoch[64] Batch [10]#011Speed: 58.32 samples/sec#011loss=5.163695\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] processed a total of 332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261190.983268, \"EndTime\": 1635261197.022426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6038.613080978394, \"count\": 1, \"min\": 6038.613080978394, \"max\": 6038.613080978394}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.97819217623294 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] #progress_metric: host=algo-1, completed 32.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=64, train loss <loss>=5.086673866618764\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] Epoch[65] Batch[0] avg_epoch_loss=5.799140\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=5.799139976501465\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:20 INFO 139626503206272] Epoch[65] Batch[5] avg_epoch_loss=5.243104\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=5.243103663126628\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:20 INFO 139626503206272] Epoch[65] Batch [5]#011Speed: 62.46 samples/sec#011loss=5.243104\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:22 INFO 139626503206272] processed a total of 302 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261197.0225205, \"EndTime\": 1635261202.3499298, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5326.829671859741, \"count\": 1, \"min\": 5326.829671859741, \"max\": 5326.829671859741}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:22 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.692757059226814 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:22 INFO 139626503206272] #progress_metric: host=algo-1, completed 33.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=65, train loss <loss>=4.975379610061646\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:22 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:23 INFO 139626503206272] Epoch[66] Batch[0] avg_epoch_loss=5.540516\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=5.540515899658203\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:25 INFO 139626503206272] Epoch[66] Batch[5] avg_epoch_loss=5.179527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=5.179527123769124\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:25 INFO 139626503206272] Epoch[66] Batch [5]#011Speed: 62.65 samples/sec#011loss=5.179527\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] Epoch[66] Batch[10] avg_epoch_loss=4.989829\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=4.762191867828369\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] Epoch[66] Batch [10]#011Speed: 62.56 samples/sec#011loss=4.762192\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] processed a total of 337 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261202.350015, \"EndTime\": 1635261208.2063315, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5855.814456939697, \"count\": 1, \"min\": 5855.814456939697, \"max\": 5855.814456939697}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.54835596505816 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] #progress_metric: host=algo-1, completed 33.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=66, train loss <loss>=4.98982928015969\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] Epoch[67] Batch[0] avg_epoch_loss=5.030195\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=5.0301947593688965\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:31 INFO 139626503206272] Epoch[67] Batch[5] avg_epoch_loss=4.951472\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=4.95147164662679\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:31 INFO 139626503206272] Epoch[67] Batch [5]#011Speed: 60.53 samples/sec#011loss=4.951472\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] Epoch[67] Batch[10] avg_epoch_loss=5.247195\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=5.602063179016113\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] Epoch[67] Batch [10]#011Speed: 62.49 samples/sec#011loss=5.602063\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] processed a total of 329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261208.206417, \"EndTime\": 1635261214.1722193, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5965.208530426025, \"count\": 1, \"min\": 5965.208530426025, \"max\": 5965.208530426025}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.15183158061674 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] #progress_metric: host=algo-1, completed 34.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=67, train loss <loss>=5.247195070440119\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] Epoch[68] Batch[0] avg_epoch_loss=4.453187\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=4.453186511993408\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:37 INFO 139626503206272] Epoch[68] Batch[5] avg_epoch_loss=5.227595\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=5.227595090866089\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:37 INFO 139626503206272] Epoch[68] Batch [5]#011Speed: 61.96 samples/sec#011loss=5.227595\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] Epoch[68] Batch[10] avg_epoch_loss=5.312022\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=5.413333988189697\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] Epoch[68] Batch [10]#011Speed: 63.32 samples/sec#011loss=5.413334\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261214.1723173, \"EndTime\": 1635261220.0897238, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5916.860580444336, \"count\": 1, \"min\": 5916.860580444336, \"max\": 5916.860580444336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.58842058865921 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] #progress_metric: host=algo-1, completed 34.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=68, train loss <loss>=5.31202186237682\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] Epoch[69] Batch[0] avg_epoch_loss=5.412948\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=5.412948131561279\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:43 INFO 139626503206272] Epoch[69] Batch[5] avg_epoch_loss=4.969153\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=4.969152847925822\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:43 INFO 139626503206272] Epoch[69] Batch [5]#011Speed: 62.97 samples/sec#011loss=4.969153\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:45 INFO 139626503206272] processed a total of 315 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261220.0898247, \"EndTime\": 1635261225.509598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5418.896675109863, \"count\": 1, \"min\": 5418.896675109863, \"max\": 5418.896675109863}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:45 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.128139519597575 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:45 INFO 139626503206272] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:45 INFO 139626503206272] #quality_metric: host=algo-1, epoch=69, train loss <loss>=5.03535041809082\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:45 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:46 INFO 139626503206272] Epoch[70] Batch[0] avg_epoch_loss=5.234843\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=5.2348432540893555\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:48 INFO 139626503206272] Epoch[70] Batch[5] avg_epoch_loss=5.103064\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=5.103064298629761\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:48 INFO 139626503206272] Epoch[70] Batch [5]#011Speed: 60.31 samples/sec#011loss=5.103064\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] processed a total of 315 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261225.5097125, \"EndTime\": 1635261231.0101142, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5499.76921081543, \"count\": 1, \"min\": 5499.76921081543, \"max\": 5499.76921081543}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.273581336280635 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] #progress_metric: host=algo-1, completed 35.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=70, train loss <loss>=5.153507709503174\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] Epoch[71] Batch[0] avg_epoch_loss=5.538377\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=5.538376808166504\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:54 INFO 139626503206272] Epoch[71] Batch[5] avg_epoch_loss=5.084602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=5.084601720174153\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:54 INFO 139626503206272] Epoch[71] Batch [5]#011Speed: 63.24 samples/sec#011loss=5.084602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] Epoch[71] Batch[10] avg_epoch_loss=5.009584\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=4.919563674926758\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] Epoch[71] Batch [10]#011Speed: 62.22 samples/sec#011loss=4.919564\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261231.0102205, \"EndTime\": 1635261236.8631911, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5852.328538894653, \"count\": 1, \"min\": 5852.328538894653, \"max\": 5852.328538894653}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.361121853501906 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] #progress_metric: host=algo-1, completed 36.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=71, train loss <loss>=5.009584426879883\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:56 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:57 INFO 139626503206272] Epoch[72] Batch[0] avg_epoch_loss=6.554335\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:13:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=6.55433464050293\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:00 INFO 139626503206272] Epoch[72] Batch[5] avg_epoch_loss=6.041583\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=6.041583220163981\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:00 INFO 139626503206272] Epoch[72] Batch [5]#011Speed: 62.65 samples/sec#011loss=6.041583\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] Epoch[72] Batch[10] avg_epoch_loss=5.813270\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=5.539293670654297\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] Epoch[72] Batch [10]#011Speed: 57.98 samples/sec#011loss=5.539294\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] processed a total of 334 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261236.8632963, \"EndTime\": 1635261242.9176447, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6053.796768188477, \"count\": 1, \"min\": 6053.796768188477, \"max\": 6053.796768188477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.17072081663995 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] #progress_metric: host=algo-1, completed 36.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=72, train loss <loss>=5.81326978856867\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:02 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:03 INFO 139626503206272] Epoch[73] Batch[0] avg_epoch_loss=5.698678\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=5.698678493499756\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:06 INFO 139626503206272] Epoch[73] Batch[5] avg_epoch_loss=5.570457\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=5.570456663767497\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:06 INFO 139626503206272] Epoch[73] Batch [5]#011Speed: 53.44 samples/sec#011loss=5.570457\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] processed a total of 312 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261242.917739, \"EndTime\": 1635261249.1421266, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6223.854303359985, \"count\": 1, \"min\": 6223.854303359985, \"max\": 6223.854303359985}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=50.12875955780663 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] #progress_metric: host=algo-1, completed 37.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=73, train loss <loss>=5.682332229614258\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] Epoch[74] Batch[0] avg_epoch_loss=5.836243\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=5.836243152618408\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:12 INFO 139626503206272] Epoch[74] Batch[5] avg_epoch_loss=5.432031\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=5.432030598322551\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:12 INFO 139626503206272] Epoch[74] Batch [5]#011Speed: 61.81 samples/sec#011loss=5.432031\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:14 INFO 139626503206272] processed a total of 303 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261249.142202, \"EndTime\": 1635261254.5305483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5387.7317905426025, \"count\": 1, \"min\": 5387.7317905426025, \"max\": 5387.7317905426025}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:14 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.23748357512537 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:14 INFO 139626503206272] #progress_metric: host=algo-1, completed 37.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=74, train loss <loss>=5.317554521560669\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:14 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:15 INFO 139626503206272] Epoch[75] Batch[0] avg_epoch_loss=5.523642\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=5.523642063140869\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:17 INFO 139626503206272] Epoch[75] Batch[5] avg_epoch_loss=5.446338\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=5.446337858835856\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:17 INFO 139626503206272] Epoch[75] Batch [5]#011Speed: 59.48 samples/sec#011loss=5.446338\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:20 INFO 139626503206272] Epoch[75] Batch[10] avg_epoch_loss=5.195941\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=4.895464134216309\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:20 INFO 139626503206272] Epoch[75] Batch [10]#011Speed: 62.02 samples/sec#011loss=4.895464\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] processed a total of 367 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261254.530641, \"EndTime\": 1635261261.0331473, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6501.765966415405, \"count\": 1, \"min\": 6501.765966415405, \"max\": 6501.765966415405}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.44493602085292 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] #progress_metric: host=algo-1, completed 38.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=75, train loss <loss>=5.2879899342854815\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] Epoch[76] Batch[0] avg_epoch_loss=4.995454\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=4.99545431137085\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:24 INFO 139626503206272] Epoch[76] Batch[5] avg_epoch_loss=4.897279\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=4.897278785705566\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:24 INFO 139626503206272] Epoch[76] Batch [5]#011Speed: 63.46 samples/sec#011loss=4.897279\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] Epoch[76] Batch[10] avg_epoch_loss=4.589489\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=4.220140862464905\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] Epoch[76] Batch [10]#011Speed: 61.93 samples/sec#011loss=4.220141\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] processed a total of 325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261261.0332465, \"EndTime\": 1635261266.9399993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5906.24475479126, \"count\": 1, \"min\": 5906.24475479126, \"max\": 5906.24475479126}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.025200041997046 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] #progress_metric: host=algo-1, completed 38.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=76, train loss <loss>=4.589488820596174\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:26 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:27 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_20cf5bc1-1192-476f-a9bf-099126c3321d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261266.9400966, \"EndTime\": 1635261267.0238853, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 83.20045471191406, \"count\": 1, \"min\": 83.20045471191406, \"max\": 83.20045471191406}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:27 INFO 139626503206272] Epoch[77] Batch[0] avg_epoch_loss=5.013737\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=5.013737201690674\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:30 INFO 139626503206272] Epoch[77] Batch[5] avg_epoch_loss=5.316991\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=5.316991249720256\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:30 INFO 139626503206272] Epoch[77] Batch [5]#011Speed: 63.22 samples/sec#011loss=5.316991\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] Epoch[77] Batch[10] avg_epoch_loss=5.474286\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=5.663039970397949\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] Epoch[77] Batch [10]#011Speed: 57.78 samples/sec#011loss=5.663040\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] processed a total of 339 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261267.0239837, \"EndTime\": 1635261273.0832515, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6059.176921844482, \"count\": 1, \"min\": 6059.176921844482, \"max\": 6059.176921844482}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.946768711638555 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] #progress_metric: host=algo-1, completed 39.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=77, train loss <loss>=5.474286122755571\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] Epoch[78] Batch[0] avg_epoch_loss=5.630941\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=5.630941390991211\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:36 INFO 139626503206272] Epoch[78] Batch[5] avg_epoch_loss=5.583991\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=5.583990732828776\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:36 INFO 139626503206272] Epoch[78] Batch [5]#011Speed: 60.61 samples/sec#011loss=5.583991\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] processed a total of 279 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261273.0833561, \"EndTime\": 1635261278.0334742, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 4949.456453323364, \"count\": 1, \"min\": 4949.456453323364, \"max\": 4949.456453323364}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.368381647507036 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] #progress_metric: host=algo-1, completed 39.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=78, train loss <loss>=5.470102151234944\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] Epoch[79] Batch[0] avg_epoch_loss=4.934662\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=4.934662342071533\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:41 INFO 139626503206272] Epoch[79] Batch[5] avg_epoch_loss=5.174619\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=5.174619197845459\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:41 INFO 139626503206272] Epoch[79] Batch [5]#011Speed: 62.97 samples/sec#011loss=5.174619\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:43 INFO 139626503206272] processed a total of 304 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261278.0335608, \"EndTime\": 1635261283.386083, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5351.9287109375, \"count\": 1, \"min\": 5351.9287109375, \"max\": 5351.9287109375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:43 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.80028239139612 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:43 INFO 139626503206272] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=79, train loss <loss>=5.150234746932983\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:43 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:44 INFO 139626503206272] Epoch[80] Batch[0] avg_epoch_loss=5.478442\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=5.478442192077637\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:46 INFO 139626503206272] Epoch[80] Batch[5] avg_epoch_loss=5.414064\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=5.414064407348633\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:46 INFO 139626503206272] Epoch[80] Batch [5]#011Speed: 62.66 samples/sec#011loss=5.414064\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:48 INFO 139626503206272] processed a total of 311 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261283.3861911, \"EndTime\": 1635261288.9103723, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5523.589611053467, \"count\": 1, \"min\": 5523.589611053467, \"max\": 5523.589611053467}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:48 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.30244924106874 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:48 INFO 139626503206272] #progress_metric: host=algo-1, completed 40.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=80, train loss <loss>=5.265010929107666\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:48 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:49 INFO 139626503206272] Epoch[81] Batch[0] avg_epoch_loss=5.216000\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=5.215999603271484\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:52 INFO 139626503206272] Epoch[81] Batch[5] avg_epoch_loss=5.322648\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=5.322648445765178\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:52 INFO 139626503206272] Epoch[81] Batch [5]#011Speed: 62.75 samples/sec#011loss=5.322648\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] Epoch[81] Batch[10] avg_epoch_loss=5.240540\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=5.142010879516602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] Epoch[81] Batch [10]#011Speed: 63.00 samples/sec#011loss=5.142011\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261288.9104743, \"EndTime\": 1635261294.7912617, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5880.262613296509, \"count\": 1, \"min\": 5880.262613296509, \"max\": 5880.262613296509}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.92826566405716 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] #progress_metric: host=algo-1, completed 41.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=81, train loss <loss>=5.240540461106733\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:54 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:55 INFO 139626503206272] Epoch[82] Batch[0] avg_epoch_loss=4.968189\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=4.968189239501953\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:58 INFO 139626503206272] Epoch[82] Batch[5] avg_epoch_loss=4.944305\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=4.944304863611857\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:14:58 INFO 139626503206272] Epoch[82] Batch [5]#011Speed: 62.44 samples/sec#011loss=4.944305\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] Epoch[82] Batch[10] avg_epoch_loss=4.978552\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=5.019647693634033\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] Epoch[82] Batch [10]#011Speed: 62.10 samples/sec#011loss=5.019648\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261294.791353, \"EndTime\": 1635261300.6986566, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5906.855344772339, \"count\": 1, \"min\": 5906.855344772339, \"max\": 5906.855344772339}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.358158647755936 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] #progress_metric: host=algo-1, completed 41.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=82, train loss <loss>=4.978551604531028\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:00 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:01 INFO 139626503206272] Epoch[83] Batch[0] avg_epoch_loss=4.668163\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=4.668163299560547\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:04 INFO 139626503206272] Epoch[83] Batch[5] avg_epoch_loss=4.820619\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=4.820619106292725\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:04 INFO 139626503206272] Epoch[83] Batch [5]#011Speed: 58.14 samples/sec#011loss=4.820619\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] Epoch[83] Batch[10] avg_epoch_loss=4.890025\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=4.973313045501709\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] Epoch[83] Batch [10]#011Speed: 51.96 samples/sec#011loss=4.973313\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] processed a total of 372 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261300.698748, \"EndTime\": 1635261307.986203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 7286.849021911621, \"count\": 1, \"min\": 7286.849021911621, \"max\": 7286.849021911621}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=51.049753353053745 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] #progress_metric: host=algo-1, completed 42.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=83, train loss <loss>=4.7775759100914\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:07 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:08 INFO 139626503206272] Epoch[84] Batch[0] avg_epoch_loss=4.937631\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=4.937630653381348\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:11 INFO 139626503206272] Epoch[84] Batch[5] avg_epoch_loss=5.072430\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=5.072430054346721\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:11 INFO 139626503206272] Epoch[84] Batch [5]#011Speed: 61.72 samples/sec#011loss=5.072430\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:13 INFO 139626503206272] processed a total of 316 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261307.9863129, \"EndTime\": 1635261313.4218926, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5434.595108032227, \"count\": 1, \"min\": 5434.595108032227, \"max\": 5434.595108032227}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:13 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.14225391809856 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:13 INFO 139626503206272] #progress_metric: host=algo-1, completed 42.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=84, train loss <loss>=5.105032873153687\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:13 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:14 INFO 139626503206272] Epoch[85] Batch[0] avg_epoch_loss=4.869240\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=4.869239807128906\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:16 INFO 139626503206272] Epoch[85] Batch[5] avg_epoch_loss=4.537345\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=4.5373445351918535\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:16 INFO 139626503206272] Epoch[85] Batch [5]#011Speed: 63.42 samples/sec#011loss=4.537345\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] Epoch[85] Batch[10] avg_epoch_loss=4.642051\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=4.767698574066162\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] Epoch[85] Batch [10]#011Speed: 58.47 samples/sec#011loss=4.767699\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] processed a total of 326 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261313.4221945, \"EndTime\": 1635261319.4748118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6052.0734786987305, \"count\": 1, \"min\": 6052.0734786987305, \"max\": 6052.0734786987305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.86452292124576 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] #progress_metric: host=algo-1, completed 43.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=85, train loss <loss>=4.642050916498357\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:19 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:20 INFO 139626503206272] Epoch[86] Batch[0] avg_epoch_loss=4.930425\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=4.930424690246582\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:22 INFO 139626503206272] Epoch[86] Batch[5] avg_epoch_loss=5.055952\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=5.055952310562134\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:22 INFO 139626503206272] Epoch[86] Batch [5]#011Speed: 62.46 samples/sec#011loss=5.055952\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:24 INFO 139626503206272] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261319.4749143, \"EndTime\": 1635261324.819052, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5343.594074249268, \"count\": 1, \"min\": 5343.594074249268, \"max\": 5343.594074249268}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:24 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=59.88317986763193 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:24 INFO 139626503206272] #progress_metric: host=algo-1, completed 43.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=86, train loss <loss>=5.217647218704224\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:24 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:25 INFO 139626503206272] Epoch[87] Batch[0] avg_epoch_loss=4.714754\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=4.7147536277771\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:28 INFO 139626503206272] Epoch[87] Batch[5] avg_epoch_loss=4.929133\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=4.92913293838501\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:28 INFO 139626503206272] Epoch[87] Batch [5]#011Speed: 62.50 samples/sec#011loss=4.929133\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] Epoch[87] Batch[10] avg_epoch_loss=5.093546\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=5.290840816497803\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] Epoch[87] Batch [10]#011Speed: 62.37 samples/sec#011loss=5.290841\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] processed a total of 325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261324.8191504, \"EndTime\": 1635261330.7251294, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5905.388832092285, \"count\": 1, \"min\": 5905.388832092285, \"max\": 5905.388832092285}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.03241976166014 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] #progress_metric: host=algo-1, completed 44.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=87, train loss <loss>=5.093545610254461\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:30 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:31 INFO 139626503206272] Epoch[88] Batch[0] avg_epoch_loss=5.168721\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=5.1687211990356445\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:34 INFO 139626503206272] Epoch[88] Batch[5] avg_epoch_loss=4.978885\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=4.97888461748759\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:34 INFO 139626503206272] Epoch[88] Batch [5]#011Speed: 61.87 samples/sec#011loss=4.978885\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] processed a total of 306 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261330.725238, \"EndTime\": 1635261336.0870569, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5361.186981201172, \"count\": 1, \"min\": 5361.186981201172, \"max\": 5361.186981201172}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.075199170654244 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] #progress_metric: host=algo-1, completed 44.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=88, train loss <loss>=4.974245262145996\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] Epoch[89] Batch[0] avg_epoch_loss=5.590209\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=5.590209007263184\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:39 INFO 139626503206272] Epoch[89] Batch[5] avg_epoch_loss=5.186937\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=5.186936775843303\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:39 INFO 139626503206272] Epoch[89] Batch [5]#011Speed: 60.29 samples/sec#011loss=5.186937\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] Epoch[89] Batch[10] avg_epoch_loss=4.963578\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=4.695546722412109\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] Epoch[89] Batch [10]#011Speed: 62.83 samples/sec#011loss=4.695547\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] processed a total of 339 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261336.0871685, \"EndTime\": 1635261342.0871692, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5999.4049072265625, \"count\": 1, \"min\": 5999.4049072265625, \"max\": 5999.4049072265625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.503318464942424 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=89, train loss <loss>=4.963577660647306\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] Epoch[90] Batch[0] avg_epoch_loss=4.929598\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=4.929598331451416\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:45 INFO 139626503206272] Epoch[90] Batch[5] avg_epoch_loss=4.719937\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:45 INFO 139626503206272] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=4.719936768213908\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:45 INFO 139626503206272] Epoch[90] Batch [5]#011Speed: 61.55 samples/sec#011loss=4.719937\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] Epoch[90] Batch[10] avg_epoch_loss=4.772088\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=4.834668684005737\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] Epoch[90] Batch [10]#011Speed: 61.34 samples/sec#011loss=4.834669\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] processed a total of 353 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261342.087255, \"EndTime\": 1635261348.5779607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6490.04340171814, \"count\": 1, \"min\": 6490.04340171814, \"max\": 6490.04340171814}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.38946710206963 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] #progress_metric: host=algo-1, completed 45.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=90, train loss <loss>=5.000065505504608\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:48 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:49 INFO 139626503206272] Epoch[91] Batch[0] avg_epoch_loss=4.550664\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=4.55066442489624\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:51 INFO 139626503206272] Epoch[91] Batch[5] avg_epoch_loss=5.109168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=5.10916789372762\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:51 INFO 139626503206272] Epoch[91] Batch [5]#011Speed: 62.71 samples/sec#011loss=5.109168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] Epoch[91] Batch[10] avg_epoch_loss=4.700859\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=4.210887682437897\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] Epoch[91] Batch [10]#011Speed: 62.53 samples/sec#011loss=4.210888\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] processed a total of 325 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261348.5780966, \"EndTime\": 1635261354.5074925, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5928.749084472656, \"count\": 1, \"min\": 5928.749084472656, \"max\": 5928.749084472656}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.81637794095163 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] #progress_metric: host=algo-1, completed 46.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=91, train loss <loss>=4.700858706777746\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:54 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:55 INFO 139626503206272] Epoch[92] Batch[0] avg_epoch_loss=4.974374\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=4.974373817443848\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:57 INFO 139626503206272] Epoch[92] Batch[5] avg_epoch_loss=5.038758\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=5.038757960001628\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:15:57 INFO 139626503206272] Epoch[92] Batch [5]#011Speed: 62.96 samples/sec#011loss=5.038758\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] Epoch[92] Batch[10] avg_epoch_loss=4.957705\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=4.860441493988037\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] Epoch[92] Batch [10]#011Speed: 60.35 samples/sec#011loss=4.860441\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] processed a total of 370 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261354.5075877, \"EndTime\": 1635261360.9564483, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6448.357582092285, \"count\": 1, \"min\": 6448.357582092285, \"max\": 6448.357582092285}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.37765788434362 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] #progress_metric: host=algo-1, completed 46.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=92, train loss <loss>=4.911800742149353\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:00 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:01 INFO 139626503206272] Epoch[93] Batch[0] avg_epoch_loss=5.147602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:01 INFO 139626503206272] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=5.14760160446167\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:04 INFO 139626503206272] Epoch[93] Batch[5] avg_epoch_loss=5.005554\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=5.005554278691609\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:04 INFO 139626503206272] Epoch[93] Batch [5]#011Speed: 52.54 samples/sec#011loss=5.005554\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] Epoch[93] Batch[10] avg_epoch_loss=5.272797\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=5.593488883972168\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] Epoch[93] Batch [10]#011Speed: 57.95 samples/sec#011loss=5.593489\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] processed a total of 333 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261360.9565425, \"EndTime\": 1635261367.6639252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6706.741809844971, \"count\": 1, \"min\": 6706.741809844971, \"max\": 6706.741809844971}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=49.65050215428363 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] #progress_metric: host=algo-1, completed 47.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=93, train loss <loss>=5.272797281091863\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:07 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:08 INFO 139626503206272] Epoch[94] Batch[0] avg_epoch_loss=5.360276\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=5.360275745391846\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:10 INFO 139626503206272] Epoch[94] Batch[5] avg_epoch_loss=5.024266\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=5.024265686670939\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:10 INFO 139626503206272] Epoch[94] Batch [5]#011Speed: 63.10 samples/sec#011loss=5.024266\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] Epoch[94] Batch[10] avg_epoch_loss=4.926724\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=4.809674263000488\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] Epoch[94] Batch [10]#011Speed: 62.55 samples/sec#011loss=4.809674\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] processed a total of 338 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261367.6640155, \"EndTime\": 1635261373.5224059, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5857.740879058838, \"count\": 1, \"min\": 5857.740879058838, \"max\": 5857.740879058838}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.700105837643655 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] #progress_metric: host=algo-1, completed 47.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=94, train loss <loss>=4.926724130457098\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:13 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:14 INFO 139626503206272] Epoch[95] Batch[0] avg_epoch_loss=4.477841\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=4.477841377258301\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:16 INFO 139626503206272] Epoch[95] Batch[5] avg_epoch_loss=4.743078\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=4.743077913920085\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:16 INFO 139626503206272] Epoch[95] Batch [5]#011Speed: 63.26 samples/sec#011loss=4.743078\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] Epoch[95] Batch[10] avg_epoch_loss=4.439015\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=4.074139952659607\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] Epoch[95] Batch [10]#011Speed: 61.66 samples/sec#011loss=4.074140\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] processed a total of 330 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261373.5224953, \"EndTime\": 1635261379.4038835, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5880.692005157471, \"count\": 1, \"min\": 5880.692005157471, \"max\": 5880.692005157471}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.11417040992136 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] #progress_metric: host=algo-1, completed 48.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=95, train loss <loss>=4.439015204256231\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:19 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/state_bd0b6829-54b7-4f42-80ea-f2f62f63dd9c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261379.4039655, \"EndTime\": 1635261379.4854739, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 80.43813705444336, \"count\": 1, \"min\": 80.43813705444336, \"max\": 80.43813705444336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:20 INFO 139626503206272] Epoch[96] Batch[0] avg_epoch_loss=5.657692\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=5.657691955566406\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:22 INFO 139626503206272] Epoch[96] Batch[5] avg_epoch_loss=4.907396\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=4.907395601272583\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:22 INFO 139626503206272] Epoch[96] Batch [5]#011Speed: 63.41 samples/sec#011loss=4.907396\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:24 INFO 139626503206272] processed a total of 311 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261379.4855657, \"EndTime\": 1635261384.8118632, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5326.15065574646, \"count\": 1, \"min\": 5326.15065574646, \"max\": 5326.15065574646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:24 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.389314004583575 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:24 INFO 139626503206272] #progress_metric: host=algo-1, completed 48.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=96, train loss <loss>=4.849485683441162\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:24 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:25 INFO 139626503206272] Epoch[97] Batch[0] avg_epoch_loss=4.959505\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=4.9595046043396\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:28 INFO 139626503206272] Epoch[97] Batch[5] avg_epoch_loss=4.841909\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=4.841908613840739\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:28 INFO 139626503206272] Epoch[97] Batch [5]#011Speed: 63.15 samples/sec#011loss=4.841909\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] Epoch[97] Batch[10] avg_epoch_loss=4.688586\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=4.5045982837677006\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] Epoch[97] Batch [10]#011Speed: 62.55 samples/sec#011loss=4.504598\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] processed a total of 332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261384.8119783, \"EndTime\": 1635261390.6997705, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5887.237548828125, \"count\": 1, \"min\": 5887.237548828125, \"max\": 5887.237548828125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.39192513306182 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] #progress_metric: host=algo-1, completed 49.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=97, train loss <loss>=4.6885857365348125\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:30 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:31 INFO 139626503206272] Epoch[98] Batch[0] avg_epoch_loss=5.421602\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=5.421602249145508\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:33 INFO 139626503206272] Epoch[98] Batch[5] avg_epoch_loss=5.146359\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=5.146359205245972\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:33 INFO 139626503206272] Epoch[98] Batch [5]#011Speed: 63.35 samples/sec#011loss=5.146359\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] processed a total of 299 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261390.6998594, \"EndTime\": 1635261396.0025883, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5302.1862506866455, \"count\": 1, \"min\": 5302.1862506866455, \"max\": 5302.1862506866455}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.39020735154581 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] #progress_metric: host=algo-1, completed 49.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=98, train loss <loss>=5.1061121940612795\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] Epoch[99] Batch[0] avg_epoch_loss=5.693697\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=5.693696975708008\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:39 INFO 139626503206272] Epoch[99] Batch[5] avg_epoch_loss=5.334885\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=5.334884564081828\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:39 INFO 139626503206272] Epoch[99] Batch [5]#011Speed: 63.40 samples/sec#011loss=5.334885\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:41 INFO 139626503206272] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261396.0026994, \"EndTime\": 1635261401.3473783, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5344.005346298218, \"count\": 1, \"min\": 5344.005346298218, \"max\": 5344.005346298218}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:41 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=59.87864888068484 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:41 INFO 139626503206272] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=99, train loss <loss>=5.174451589584351\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:41 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:42 INFO 139626503206272] Epoch[100] Batch[0] avg_epoch_loss=5.144217\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=5.144217014312744\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:44 INFO 139626503206272] Epoch[100] Batch[5] avg_epoch_loss=4.737100\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=4.737100283304851\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:44 INFO 139626503206272] Epoch[100] Batch [5]#011Speed: 63.20 samples/sec#011loss=4.737100\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:46 INFO 139626503206272] processed a total of 309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261401.347465, \"EndTime\": 1635261406.6519008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5303.852796554565, \"count\": 1, \"min\": 5303.852796554565, \"max\": 5303.852796554565}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:46 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.25781489221647 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:46 INFO 139626503206272] #progress_metric: host=algo-1, completed 50.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=100, train loss <loss>=4.639535140991211\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:46 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:47 INFO 139626503206272] Epoch[101] Batch[0] avg_epoch_loss=4.384378\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=4.384378433227539\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:50 INFO 139626503206272] Epoch[101] Batch[5] avg_epoch_loss=4.614173\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=4.614172538121541\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:50 INFO 139626503206272] Epoch[101] Batch [5]#011Speed: 59.12 samples/sec#011loss=4.614173\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] processed a total of 308 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261406.6520073, \"EndTime\": 1635261412.1922202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5539.644956588745, \"count\": 1, \"min\": 5539.644956588745, \"max\": 5539.644956588745}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.597773826363756 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] #progress_metric: host=algo-1, completed 51.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=101, train loss <loss>=4.93254919052124\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] Epoch[102] Batch[0] avg_epoch_loss=5.113530\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:52 INFO 139626503206272] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=5.113530158996582\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:55 INFO 139626503206272] Epoch[102] Batch[5] avg_epoch_loss=4.807502\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:55 INFO 139626503206272] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=4.807502468427022\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:55 INFO 139626503206272] Epoch[102] Batch [5]#011Speed: 62.89 samples/sec#011loss=4.807502\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:57 INFO 139626503206272] processed a total of 297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261412.1923194, \"EndTime\": 1635261417.5362551, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5343.3592319488525, \"count\": 1, \"min\": 5343.3592319488525, \"max\": 5343.3592319488525}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:57 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.58175704379302 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:57 INFO 139626503206272] #progress_metric: host=algo-1, completed 51.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=102, train loss <loss>=5.001437306404114\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:57 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:58 INFO 139626503206272] Epoch[103] Batch[0] avg_epoch_loss=5.399291\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:16:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=5.399290561676025\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:00 INFO 139626503206272] Epoch[103] Batch[5] avg_epoch_loss=4.867116\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=4.867115577061971\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:00 INFO 139626503206272] Epoch[103] Batch [5]#011Speed: 63.04 samples/sec#011loss=4.867116\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:03 INFO 139626503206272] processed a total of 296 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261417.5363314, \"EndTime\": 1635261423.2066717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5669.771432876587, \"count\": 1, \"min\": 5669.771432876587, \"max\": 5669.771432876587}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:03 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=52.205329004453695 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:03 INFO 139626503206272] #progress_metric: host=algo-1, completed 52.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=103, train loss <loss>=4.983708333969116\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:03 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:04 INFO 139626503206272] Epoch[104] Batch[0] avg_epoch_loss=5.247550\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=5.2475504875183105\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:07 INFO 139626503206272] Epoch[104] Batch[5] avg_epoch_loss=5.236224\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:07 INFO 139626503206272] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=5.236224253972371\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:07 INFO 139626503206272] Epoch[104] Batch [5]#011Speed: 52.60 samples/sec#011loss=5.236224\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:09 INFO 139626503206272] Epoch[104] Batch[10] avg_epoch_loss=5.158606\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=5.065465068817138\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:09 INFO 139626503206272] Epoch[104] Batch [10]#011Speed: 61.85 samples/sec#011loss=5.065465\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] processed a total of 353 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261423.2067714, \"EndTime\": 1635261430.19342, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6986.011743545532, \"count\": 1, \"min\": 6986.011743545532, \"max\": 6986.011743545532}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=50.52826105014224 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 52.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=104, train loss <loss>=5.1121218999226885\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] Epoch[105] Batch[0] avg_epoch_loss=5.190283\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=5.190283298492432\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:13 INFO 139626503206272] Epoch[105] Batch[5] avg_epoch_loss=5.314123\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=5.314122915267944\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:13 INFO 139626503206272] Epoch[105] Batch [5]#011Speed: 63.35 samples/sec#011loss=5.314123\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] Epoch[105] Batch[10] avg_epoch_loss=5.378128\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=5.454933547973633\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] Epoch[105] Batch [10]#011Speed: 62.22 samples/sec#011loss=5.454934\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] processed a total of 322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261430.1935246, \"EndTime\": 1635261436.0682485, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5874.160051345825, \"count\": 1, \"min\": 5874.160051345825, \"max\": 5874.160051345825}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.81509738286407 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] #progress_metric: host=algo-1, completed 53.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=105, train loss <loss>=5.378127748315984\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] Epoch[106] Batch[0] avg_epoch_loss=4.813317\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:16 INFO 139626503206272] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=4.813316822052002\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:19 INFO 139626503206272] Epoch[106] Batch[5] avg_epoch_loss=5.125021\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=5.12502106030782\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:19 INFO 139626503206272] Epoch[106] Batch [5]#011Speed: 60.75 samples/sec#011loss=5.125021\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:21 INFO 139626503206272] processed a total of 313 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261436.0683405, \"EndTime\": 1635261441.6848145, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5615.979909896851, \"count\": 1, \"min\": 5615.979909896851, \"max\": 5615.979909896851}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:21 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.73219451181753 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:21 INFO 139626503206272] #progress_metric: host=algo-1, completed 53.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:21 INFO 139626503206272] #quality_metric: host=algo-1, epoch=106, train loss <loss>=5.210024881362915\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:21 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:22 INFO 139626503206272] Epoch[107] Batch[0] avg_epoch_loss=4.995835\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=4.995834827423096\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:25 INFO 139626503206272] Epoch[107] Batch[5] avg_epoch_loss=4.639300\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=4.6392998695373535\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:25 INFO 139626503206272] Epoch[107] Batch [5]#011Speed: 62.55 samples/sec#011loss=4.639300\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:27 INFO 139626503206272] Epoch[107] Batch[10] avg_epoch_loss=4.910909\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:27 INFO 139626503206272] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=5.236838912963867\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:27 INFO 139626503206272] Epoch[107] Batch [10]#011Speed: 62.24 samples/sec#011loss=5.236839\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] processed a total of 356 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261441.6849282, \"EndTime\": 1635261448.0824435, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6396.907567977905, \"count\": 1, \"min\": 6396.907567977905, \"max\": 6396.907567977905}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.65045734330985 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] #progress_metric: host=algo-1, completed 54.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=107, train loss <loss>=4.91726283232371\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] Epoch[108] Batch[0] avg_epoch_loss=4.725205\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=4.725205421447754\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:31 INFO 139626503206272] Epoch[108] Batch[5] avg_epoch_loss=4.929136\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=4.929136196772258\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:31 INFO 139626503206272] Epoch[108] Batch [5]#011Speed: 61.70 samples/sec#011loss=4.929136\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] Epoch[108] Batch[10] avg_epoch_loss=4.543944\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=4.081714448332787\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] Epoch[108] Batch [10]#011Speed: 63.03 samples/sec#011loss=4.081714\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] processed a total of 324 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261448.0825584, \"EndTime\": 1635261453.9971843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5913.816452026367, \"count\": 1, \"min\": 5913.816452026367, \"max\": 5913.816452026367}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.7856459381453 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] #progress_metric: host=algo-1, completed 54.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] #quality_metric: host=algo-1, epoch=108, train loss <loss>=4.543944492936134\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:33 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:34 INFO 139626503206272] Epoch[109] Batch[0] avg_epoch_loss=5.925526\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=5.925525665283203\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:37 INFO 139626503206272] Epoch[109] Batch[5] avg_epoch_loss=5.366110\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=5.366109848022461\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:37 INFO 139626503206272] Epoch[109] Batch [5]#011Speed: 61.94 samples/sec#011loss=5.366110\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] Epoch[109] Batch[10] avg_epoch_loss=5.345487\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=5.320740127563477\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] Epoch[109] Batch [10]#011Speed: 61.38 samples/sec#011loss=5.320740\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] processed a total of 331 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261453.9972827, \"EndTime\": 1635261459.995069, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5997.209787368774, \"count\": 1, \"min\": 5997.209787368774, \"max\": 5997.209787368774}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.19103633545874 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=109, train loss <loss>=5.345487247813832\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:39 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:40 INFO 139626503206272] Epoch[110] Batch[0] avg_epoch_loss=4.922814\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:40 INFO 139626503206272] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=4.922813892364502\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:43 INFO 139626503206272] Epoch[110] Batch[5] avg_epoch_loss=5.066101\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=5.066100994745891\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:43 INFO 139626503206272] Epoch[110] Batch [5]#011Speed: 62.67 samples/sec#011loss=5.066101\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:45 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261459.9951665, \"EndTime\": 1635261465.4072707, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5411.523342132568, \"count\": 1, \"min\": 5411.523342132568, \"max\": 5411.523342132568}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:45 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.57622980095056 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:45 INFO 139626503206272] #progress_metric: host=algo-1, completed 55.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:45 INFO 139626503206272] #quality_metric: host=algo-1, epoch=110, train loss <loss>=4.808874773979187\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:45 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:46 INFO 139626503206272] Epoch[111] Batch[0] avg_epoch_loss=5.484547\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:46 INFO 139626503206272] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=5.484546661376953\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:48 INFO 139626503206272] Epoch[111] Batch[5] avg_epoch_loss=4.683920\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=4.68391998608907\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:48 INFO 139626503206272] Epoch[111] Batch [5]#011Speed: 63.29 samples/sec#011loss=4.683920\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:50 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261465.4074528, \"EndTime\": 1635261470.8470252, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5438.8837814331055, \"count\": 1, \"min\": 5438.8837814331055, \"max\": 5438.8837814331055}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:50 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.28242372448358 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:50 INFO 139626503206272] #progress_metric: host=algo-1, completed 56.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=111, train loss <loss>=4.8574117660522464\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:50 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:51 INFO 139626503206272] Epoch[112] Batch[0] avg_epoch_loss=5.520123\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=5.520123481750488\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:54 INFO 139626503206272] Epoch[112] Batch[5] avg_epoch_loss=5.088370\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=5.088370323181152\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:54 INFO 139626503206272] Epoch[112] Batch [5]#011Speed: 63.54 samples/sec#011loss=5.088370\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] Epoch[112] Batch[10] avg_epoch_loss=4.584054\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=3.9788742870092393\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] Epoch[112] Batch [10]#011Speed: 62.32 samples/sec#011loss=3.978874\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] processed a total of 321 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261470.847128, \"EndTime\": 1635261476.7641013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5916.117429733276, \"count\": 1, \"min\": 5916.117429733276, \"max\": 5916.117429733276}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.2572656259508 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] #progress_metric: host=algo-1, completed 56.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=112, train loss <loss>=4.58405394310301\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:56 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:57 INFO 139626503206272] Epoch[113] Batch[0] avg_epoch_loss=5.581326\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:17:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=5.581325531005859\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:00 INFO 139626503206272] Epoch[113] Batch[5] avg_epoch_loss=5.311841\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:00 INFO 139626503206272] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=5.311841249465942\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:00 INFO 139626503206272] Epoch[113] Batch [5]#011Speed: 62.13 samples/sec#011loss=5.311841\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:02 INFO 139626503206272] processed a total of 308 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261476.764199, \"EndTime\": 1635261482.3071103, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5542.428016662598, \"count\": 1, \"min\": 5542.428016662598, \"max\": 5542.428016662598}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:02 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.567791623066334 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:02 INFO 139626503206272] #progress_metric: host=algo-1, completed 57.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=113, train loss <loss>=5.100648903846741\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:02 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:03 INFO 139626503206272] Epoch[114] Batch[0] avg_epoch_loss=6.090377\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:03 INFO 139626503206272] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=6.090376853942871\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:06 INFO 139626503206272] Epoch[114] Batch[5] avg_epoch_loss=5.050891\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=5.050890525182088\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:06 INFO 139626503206272] Epoch[114] Batch [5]#011Speed: 50.07 samples/sec#011loss=5.050891\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:08 INFO 139626503206272] processed a total of 310 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261482.3072066, \"EndTime\": 1635261488.4348881, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6126.850843429565, \"count\": 1, \"min\": 6126.850843429565, \"max\": 6126.850843429565}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:08 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=50.59587270426106 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:08 INFO 139626503206272] #progress_metric: host=algo-1, completed 57.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=114, train loss <loss>=5.192769718170166\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:08 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:09 INFO 139626503206272] Epoch[115] Batch[0] avg_epoch_loss=4.860408\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=4.860408306121826\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:11 INFO 139626503206272] Epoch[115] Batch[5] avg_epoch_loss=4.986933\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=4.9869325160980225\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:11 INFO 139626503206272] Epoch[115] Batch [5]#011Speed: 62.62 samples/sec#011loss=4.986933\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:13 INFO 139626503206272] processed a total of 316 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261488.4349794, \"EndTime\": 1635261493.7761185, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5340.377569198608, \"count\": 1, \"min\": 5340.377569198608, \"max\": 5340.377569198608}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:13 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=59.170070999171024 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:13 INFO 139626503206272] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:13 INFO 139626503206272] #quality_metric: host=algo-1, epoch=115, train loss <loss>=5.023446702957154\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:13 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:14 INFO 139626503206272] Epoch[116] Batch[0] avg_epoch_loss=4.751983\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:14 INFO 139626503206272] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=4.751982688903809\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:17 INFO 139626503206272] Epoch[116] Batch[5] avg_epoch_loss=4.933815\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=4.933814764022827\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:17 INFO 139626503206272] Epoch[116] Batch [5]#011Speed: 62.14 samples/sec#011loss=4.933815\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] processed a total of 315 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261493.7762296, \"EndTime\": 1635261499.1727664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5395.959138870239, \"count\": 1, \"min\": 5395.959138870239, \"max\": 5395.959138870239}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.37524274862423 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=116, train loss <loss>=4.886658143997193\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] Epoch[117] Batch[0] avg_epoch_loss=4.750542\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:19 INFO 139626503206272] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=4.750542163848877\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:22 INFO 139626503206272] Epoch[117] Batch[5] avg_epoch_loss=4.908057\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:22 INFO 139626503206272] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=4.90805721282959\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:22 INFO 139626503206272] Epoch[117] Batch [5]#011Speed: 58.54 samples/sec#011loss=4.908057\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] Epoch[117] Batch[10] avg_epoch_loss=5.004139\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=5.119437789916992\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] Epoch[117] Batch [10]#011Speed: 62.78 samples/sec#011loss=5.119438\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] processed a total of 328 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261499.1728835, \"EndTime\": 1635261505.1921618, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6018.645286560059, \"count\": 1, \"min\": 6018.645286560059, \"max\": 6018.645286560059}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.49618462217847 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=117, train loss <loss>=5.004139293323863\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] Epoch[118] Batch[0] avg_epoch_loss=4.923384\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:25 INFO 139626503206272] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=4.923383712768555\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:28 INFO 139626503206272] Epoch[118] Batch[5] avg_epoch_loss=4.942982\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:28 INFO 139626503206272] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=4.942981719970703\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:28 INFO 139626503206272] Epoch[118] Batch [5]#011Speed: 63.18 samples/sec#011loss=4.942982\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] Epoch[118] Batch[10] avg_epoch_loss=4.634540\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=4.2644106388092045\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] Epoch[118] Batch [10]#011Speed: 62.55 samples/sec#011loss=4.264411\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] processed a total of 339 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261505.192243, \"EndTime\": 1635261511.0608058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5867.95449256897, \"count\": 1, \"min\": 5867.95449256897, \"max\": 5867.95449256897}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.770043084087895 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] #progress_metric: host=algo-1, completed 59.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=118, train loss <loss>=4.634540319442749\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] Epoch[119] Batch[0] avg_epoch_loss=4.393316\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:31 INFO 139626503206272] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=4.393316268920898\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:34 INFO 139626503206272] Epoch[119] Batch[5] avg_epoch_loss=4.984453\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:34 INFO 139626503206272] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=4.984452565511067\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:34 INFO 139626503206272] Epoch[119] Batch [5]#011Speed: 63.05 samples/sec#011loss=4.984453\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:36 INFO 139626503206272] processed a total of 316 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261511.0609024, \"EndTime\": 1635261516.5254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5463.979005813599, \"count\": 1, \"min\": 5463.979005813599, \"max\": 5463.979005813599}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:36 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.831577907518 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:36 INFO 139626503206272] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=119, train loss <loss>=5.0345899105072025\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:36 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:37 INFO 139626503206272] Epoch[120] Batch[0] avg_epoch_loss=4.113036\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:37 INFO 139626503206272] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=4.113035678863525\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:39 INFO 139626503206272] Epoch[120] Batch[5] avg_epoch_loss=4.844540\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:39 INFO 139626503206272] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=4.844540357589722\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:39 INFO 139626503206272] Epoch[120] Batch [5]#011Speed: 63.27 samples/sec#011loss=4.844540\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] Epoch[120] Batch[10] avg_epoch_loss=5.073952\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=5.349244880676269\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] Epoch[120] Batch [10]#011Speed: 62.34 samples/sec#011loss=5.349245\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] processed a total of 321 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261516.5255132, \"EndTime\": 1635261522.4437718, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5917.280197143555, \"count\": 1, \"min\": 5917.280197143555, \"max\": 5917.280197143555}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.24666313932355 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] #progress_metric: host=algo-1, completed 60.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] #quality_metric: host=algo-1, epoch=120, train loss <loss>=5.073951504447243\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:42 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:43 INFO 139626503206272] Epoch[121] Batch[0] avg_epoch_loss=5.417005\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:43 INFO 139626503206272] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=5.4170050621032715\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:45 INFO 139626503206272] Epoch[121] Batch[5] avg_epoch_loss=4.733742\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:45 INFO 139626503206272] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=4.733741839726766\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:45 INFO 139626503206272] Epoch[121] Batch [5]#011Speed: 63.22 samples/sec#011loss=4.733742\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] Epoch[121] Batch[10] avg_epoch_loss=4.878048\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=5.051216411590576\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] Epoch[121] Batch [10]#011Speed: 62.03 samples/sec#011loss=5.051216\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] processed a total of 338 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261522.4438639, \"EndTime\": 1635261528.3348212, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5890.484094619751, \"count\": 1, \"min\": 5890.484094619751, \"max\": 5890.484094619751}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.3792894433786 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] #progress_metric: host=algo-1, completed 61.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] #quality_metric: host=algo-1, epoch=121, train loss <loss>=4.8780484633012255\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:48 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:49 INFO 139626503206272] Epoch[122] Batch[0] avg_epoch_loss=5.245342\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:49 INFO 139626503206272] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=5.245342254638672\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:51 INFO 139626503206272] Epoch[122] Batch[5] avg_epoch_loss=4.791269\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:51 INFO 139626503206272] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=4.791268984476726\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:51 INFO 139626503206272] Epoch[122] Batch [5]#011Speed: 61.77 samples/sec#011loss=4.791269\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:53 INFO 139626503206272] processed a total of 296 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261528.3349168, \"EndTime\": 1635261533.8818333, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5546.287775039673, \"count\": 1, \"min\": 5546.287775039673, \"max\": 5546.287775039673}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:53 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.367761592580955 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:53 INFO 139626503206272] #progress_metric: host=algo-1, completed 61.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=122, train loss <loss>=4.726513338088989\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:53 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:54 INFO 139626503206272] Epoch[123] Batch[0] avg_epoch_loss=4.363836\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:54 INFO 139626503206272] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=4.363836288452148\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:57 INFO 139626503206272] Epoch[123] Batch[5] avg_epoch_loss=4.733386\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:57 INFO 139626503206272] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=4.733386317888896\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:57 INFO 139626503206272] Epoch[123] Batch [5]#011Speed: 62.37 samples/sec#011loss=4.733386\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] processed a total of 306 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261533.8819263, \"EndTime\": 1635261539.227928, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5345.155715942383, \"count\": 1, \"min\": 5345.155715942383, \"max\": 5345.155715942383}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.24581811651964 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] #progress_metric: host=algo-1, completed 62.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=123, train loss <loss>=4.456942081451416\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] Epoch[124] Batch[0] avg_epoch_loss=4.716162\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:18:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=4.716161727905273\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:02 INFO 139626503206272] Epoch[124] Batch[5] avg_epoch_loss=5.153118\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=5.15311845143636\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:02 INFO 139626503206272] Epoch[124] Batch [5]#011Speed: 57.21 samples/sec#011loss=5.153118\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] Epoch[124] Batch[10] avg_epoch_loss=4.863407\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=4.515752172470092\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] Epoch[124] Batch [10]#011Speed: 49.32 samples/sec#011loss=4.515752\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] processed a total of 334 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261539.2280347, \"EndTime\": 1635261546.0282009, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6799.536943435669, \"count\": 1, \"min\": 6799.536943435669, \"max\": 6799.536943435669}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=49.11997068154263 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] #progress_metric: host=algo-1, completed 62.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=124, train loss <loss>=4.863406506451693\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] Epoch[125] Batch[0] avg_epoch_loss=5.136137\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:06 INFO 139626503206272] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=5.136136531829834\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:09 INFO 139626503206272] Epoch[125] Batch[5] avg_epoch_loss=4.707652\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:09 INFO 139626503206272] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=4.7076520919799805\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:09 INFO 139626503206272] Epoch[125] Batch [5]#011Speed: 62.83 samples/sec#011loss=4.707652\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] Epoch[125] Batch[10] avg_epoch_loss=4.942620\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=5.224581718444824\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] Epoch[125] Batch [10]#011Speed: 62.32 samples/sec#011loss=5.224582\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] processed a total of 338 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261546.0283005, \"EndTime\": 1635261551.9074395, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5878.543138504028, \"count\": 1, \"min\": 5878.543138504028, \"max\": 5878.543138504028}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.49591218968303 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] #progress_metric: host=algo-1, completed 63.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] #quality_metric: host=algo-1, epoch=125, train loss <loss>=4.942620104009455\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:11 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:12 INFO 139626503206272] Epoch[126] Batch[0] avg_epoch_loss=4.877083\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:12 INFO 139626503206272] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=4.8770833015441895\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:15 INFO 139626503206272] Epoch[126] Batch[5] avg_epoch_loss=5.117866\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:15 INFO 139626503206272] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=5.1178657213846845\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:15 INFO 139626503206272] Epoch[126] Batch [5]#011Speed: 62.98 samples/sec#011loss=5.117866\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:17 INFO 139626503206272] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261551.9075317, \"EndTime\": 1635261557.437155, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5529.163360595703, \"count\": 1, \"min\": 5529.163360595703, \"max\": 5529.163360595703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:17 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.33082765739494 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:17 INFO 139626503206272] #progress_metric: host=algo-1, completed 63.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:17 INFO 139626503206272] #quality_metric: host=algo-1, epoch=126, train loss <loss>=4.985608434677124\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:17 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:18 INFO 139626503206272] Epoch[127] Batch[0] avg_epoch_loss=5.180250\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:18 INFO 139626503206272] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=5.1802496910095215\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:20 INFO 139626503206272] Epoch[127] Batch[5] avg_epoch_loss=4.804068\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:20 INFO 139626503206272] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=4.804067691167195\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:20 INFO 139626503206272] Epoch[127] Batch [5]#011Speed: 63.72 samples/sec#011loss=4.804068\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] Epoch[127] Batch[10] avg_epoch_loss=5.046504\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=5.337427043914795\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] Epoch[127] Batch [10]#011Speed: 57.89 samples/sec#011loss=5.337427\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] processed a total of 333 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261557.4372563, \"EndTime\": 1635261563.51845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 6080.610036849976, \"count\": 1, \"min\": 6080.610036849976, \"max\": 6080.610036849976}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=54.76297090723413 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] #progress_metric: host=algo-1, completed 64.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] #quality_metric: host=algo-1, epoch=127, train loss <loss>=5.046503760597923\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:23 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:24 INFO 139626503206272] Epoch[128] Batch[0] avg_epoch_loss=5.236566\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:24 INFO 139626503206272] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=5.236566066741943\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:26 INFO 139626503206272] Epoch[128] Batch[5] avg_epoch_loss=5.204798\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:26 INFO 139626503206272] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=5.204797665278117\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:26 INFO 139626503206272] Epoch[128] Batch [5]#011Speed: 63.15 samples/sec#011loss=5.204798\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] Epoch[128] Batch[10] avg_epoch_loss=5.395666\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=5.624708652496338\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] Epoch[128] Batch [10]#011Speed: 61.33 samples/sec#011loss=5.624709\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] processed a total of 333 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261563.5185473, \"EndTime\": 1635261569.4201245, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5901.00359916687, \"count\": 1, \"min\": 5901.00359916687, \"max\": 5901.00359916687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.42965171547643 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] #progress_metric: host=algo-1, completed 64.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] #quality_metric: host=algo-1, epoch=128, train loss <loss>=5.3956662958318535\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:29 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:30 INFO 139626503206272] Epoch[129] Batch[0] avg_epoch_loss=4.258910\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:30 INFO 139626503206272] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=4.258910179138184\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:32 INFO 139626503206272] Epoch[129] Batch[5] avg_epoch_loss=5.103961\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:32 INFO 139626503206272] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=5.1039613087972\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:32 INFO 139626503206272] Epoch[129] Batch [5]#011Speed: 62.63 samples/sec#011loss=5.103961\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] Epoch[129] Batch[10] avg_epoch_loss=4.734494\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=4.291132390499115\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] Epoch[129] Batch [10]#011Speed: 63.09 samples/sec#011loss=4.291132\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261569.4202235, \"EndTime\": 1635261575.269198, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5848.4649658203125, \"count\": 1, \"min\": 5848.4649658203125, \"max\": 5848.4649658203125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=55.22580312735286 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] #quality_metric: host=algo-1, epoch=129, train loss <loss>=4.734493618661707\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:35 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:36 INFO 139626503206272] Epoch[130] Batch[0] avg_epoch_loss=7.065438\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:36 INFO 139626503206272] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=7.0654377937316895\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:38 INFO 139626503206272] Epoch[130] Batch[5] avg_epoch_loss=5.883977\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:38 INFO 139626503206272] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=5.883976697921753\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:38 INFO 139626503206272] Epoch[130] Batch [5]#011Speed: 61.98 samples/sec#011loss=5.883977\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] Epoch[130] Batch[10] avg_epoch_loss=5.725525\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=5.535383510589599\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] Epoch[130] Batch [10]#011Speed: 63.02 samples/sec#011loss=5.535384\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] processed a total of 332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261575.2694006, \"EndTime\": 1635261581.1518767, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5881.831884384155, \"count\": 1, \"min\": 5881.831884384155, \"max\": 5881.831884384155}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.44381015204629 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] #progress_metric: host=algo-1, completed 65.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=130, train loss <loss>=5.72552524913441\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] Epoch[131] Batch[0] avg_epoch_loss=5.630197\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:41 INFO 139626503206272] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=5.630196571350098\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:44 INFO 139626503206272] Epoch[131] Batch[5] avg_epoch_loss=5.300107\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:44 INFO 139626503206272] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=5.3001073996226\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:44 INFO 139626503206272] Epoch[131] Batch [5]#011Speed: 61.60 samples/sec#011loss=5.300107\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] Epoch[131] Batch[10] avg_epoch_loss=5.248054\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=5.18558988571167\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] Epoch[131] Batch [10]#011Speed: 62.37 samples/sec#011loss=5.185590\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] processed a total of 343 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261581.1519554, \"EndTime\": 1635261587.051494, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5898.961305618286, \"count\": 1, \"min\": 5898.961305618286, \"max\": 5898.961305618286}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=58.144405672425535 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] #progress_metric: host=algo-1, completed 66.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=131, train loss <loss>=5.24805398420854\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] Epoch[132] Batch[0] avg_epoch_loss=5.450289\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:47 INFO 139626503206272] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=5.450288772583008\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:50 INFO 139626503206272] Epoch[132] Batch[5] avg_epoch_loss=5.205532\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:50 INFO 139626503206272] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=5.20553191502889\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:50 INFO 139626503206272] Epoch[132] Batch [5]#011Speed: 62.83 samples/sec#011loss=5.205532\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] Epoch[132] Batch[10] avg_epoch_loss=4.959411\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=4.664065265655518\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] Epoch[132] Batch [10]#011Speed: 60.35 samples/sec#011loss=4.664065\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] processed a total of 342 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261587.0515912, \"EndTime\": 1635261593.0155072, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5963.261365890503, \"count\": 1, \"min\": 5963.261365890503, \"max\": 5963.261365890503}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=57.34972272309679 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] #progress_metric: host=algo-1, completed 66.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=132, train loss <loss>=4.959410710768267\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] Epoch[133] Batch[0] avg_epoch_loss=5.311220\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:53 INFO 139626503206272] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=5.311220169067383\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:56 INFO 139626503206272] Epoch[133] Batch[5] avg_epoch_loss=4.868282\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:56 INFO 139626503206272] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=4.868281523386638\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:56 INFO 139626503206272] Epoch[133] Batch [5]#011Speed: 63.75 samples/sec#011loss=4.868282\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] Epoch[133] Batch[10] avg_epoch_loss=4.589803\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=4.255629301071167\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] Epoch[133] Batch [10]#011Speed: 61.71 samples/sec#011loss=4.255629\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] processed a total of 333 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261593.0156054, \"EndTime\": 1635261598.9281976, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5911.596775054932, \"count\": 1, \"min\": 5911.596775054932, \"max\": 5911.596775054932}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.32855664890589 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] #progress_metric: host=algo-1, completed 67.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] #quality_metric: host=algo-1, epoch=133, train loss <loss>=4.589803240515969\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:58 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:59 INFO 139626503206272] Epoch[134] Batch[0] avg_epoch_loss=5.204971\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:19:59 INFO 139626503206272] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=5.204970836639404\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:02 INFO 139626503206272] Epoch[134] Batch[5] avg_epoch_loss=4.790477\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:02 INFO 139626503206272] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=4.790477275848389\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:02 INFO 139626503206272] Epoch[134] Batch [5]#011Speed: 60.07 samples/sec#011loss=4.790477\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:04 INFO 139626503206272] processed a total of 318 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261598.9282978, \"EndTime\": 1635261604.880304, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5951.385021209717, \"count\": 1, \"min\": 5951.385021209717, \"max\": 5951.385021209717}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:04 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=53.43128131247698 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:04 INFO 139626503206272] #progress_metric: host=algo-1, completed 67.5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:04 INFO 139626503206272] #quality_metric: host=algo-1, epoch=134, train loss <loss>=4.868662118911743\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:04 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:05 INFO 139626503206272] Epoch[135] Batch[0] avg_epoch_loss=4.589892\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:05 INFO 139626503206272] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=4.5898919105529785\u001b[0m\n",
      "\n",
      "2021-10-26 15:20:23 Uploading - Uploading generated training model\u001b[34m[10/26/2021 15:20:08 INFO 139626503206272] Epoch[135] Batch[5] avg_epoch_loss=4.514391\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:08 INFO 139626503206272] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=4.514391183853149\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:08 INFO 139626503206272] Epoch[135] Batch [5]#011Speed: 61.91 samples/sec#011loss=4.514391\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261604.8804395, \"EndTime\": 1635261610.5677154, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 5686.631202697754, \"count\": 1, \"min\": 5686.631202697754, \"max\": 5686.631202697754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] #throughput_metric: host=algo-1, train throughput=56.270893050372564 records/second\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 68.0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] #quality_metric: host=algo-1, epoch=135, train loss <loss>=4.611437273025513\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] Loading parameters from best epoch (95)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261610.5678177, \"EndTime\": 1635261610.6036437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 35.08353233337402, \"count\": 1, \"min\": 35.08353233337402, \"max\": 35.08353233337402}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] stopping training now\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] Final loss: 4.439015204256231 (occurred at epoch 95)\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] #quality_metric: host=algo-1, train final_loss <loss>=4.439015204256231\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 WARNING 139626503206272] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:10 INFO 139626503206272] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261610.6037273, \"EndTime\": 1635261611.3114233, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 706.8254947662354, \"count\": 1, \"min\": 706.8254947662354, \"max\": 706.8254947662354}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261611.3115125, \"EndTime\": 1635261611.603868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 999.316930770874, \"count\": 1, \"min\": 999.316930770874, \"max\": 999.316930770874}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261611.6039708, \"EndTime\": 1635261611.648318, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 44.2957878112793, \"count\": 1, \"min\": 44.2957878112793, \"max\": 44.2957878112793}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] #memory_usage::<batchbuffer> = 12.597084045410156 mb\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:11 INFO 139626503206272] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261611.6483839, \"EndTime\": 1635261611.6495004, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.04482269287109375, \"count\": 1, \"min\": 0.04482269287109375, \"max\": 0.04482269287109375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261611.6495728, \"EndTime\": 1635261618.9320314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 7282.572984695435, \"count\": 1, \"min\": 7282.572984695435, \"max\": 7282.572984695435}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, RMSE): 13512.131727533677\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, mean_absolute_QuantileLoss): 912761.0046875001\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, mean_wQuantileLoss): 0.1848249190369295\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.1]): 0.06557031403291212\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.2]): 0.11781567551681\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.3]): 0.1609803198985394\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.4]): 0.19589212586491045\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.5]): 0.22144824407180333\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.6]): 0.2374599857735632\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.7]): 0.2435401930566909\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.8]): 0.23275411297561596\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #test_score (algo-1, wQuantileLoss[0.9]): 0.1879633001415202\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #quality_metric: host=algo-1, test RMSE <loss>=13512.131727533677\u001b[0m\n",
      "\u001b[34m[10/26/2021 15:20:18 INFO 139626503206272] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.1848249190369295\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1635261618.9321446, \"EndTime\": 1635261619.0060754, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 8.685827255249023, \"count\": 1, \"min\": 8.685827255249023, \"max\": 8.685827255249023}, \"totaltime\": {\"sum\": 796547.5323200226, \"count\": 1, \"min\": 796547.5323200226, \"max\": 796547.5323200226}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-10-26 15:20:58 Completed - Training job completed\n",
      "ProfilerReport-1635260419: NoIssuesFound\n",
      "Training seconds: 848\n",
      "Billable seconds: 848\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "data_channels = {\"train\": train_path, \"test\": test_path}\n",
    "\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b8c8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46529beb",
   "metadata": {},
   "source": [
    "Training Results\n",
    "\n",
    "starting loss: 7.334874\n",
    "Final loss: 4.602022239091721\n",
    "\n",
    "\n",
    "#test_score (algo-1, RMSE): 4559.286415901311\n",
    "\n",
    "#test_score (algo-1, mean_absolute_QuantileLoss): 252814.03333333335\n",
    "\n",
    "#test_score (algo-1, mean_wQuantileLoss): 0.05119229787673776\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.1]): 0.026615664524137515\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.2]): 0.035788473100831684\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.3]): 0.04361698768198024\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.4]): 0.05539865067286393\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.5]): 0.06399183037893764\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.6]): 0.06572183859800423\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.7]): 0.06510322582670063\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.8]): 0.06001858800678422\n",
    "\n",
    "#test_score (algo-1, wQuantileLoss[0.9]): 0.04447542210039976\n",
    "\n",
    "#quality_metric: host=algo-1, test RMSE <loss>=4559.286415901311\n",
    "    \n",
    "#quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.05119229787673776\n",
    "\n",
    "bitcoin-predictor-2021-10-26-14-29-04-775\tarn:aws:sagemaker:us-east-1:237845067016:endpoint/bitcoin-predictor-2021-10-26-14-29-04-775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298bef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a8d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538b9525",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e329f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from S3\n",
    "model = sagemaker.model.Model(\n",
    "    image_uri='522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:1',\n",
    "    model_data='s3://sagemaker-us-east-1-237845067016/bitcoin-prediction/output/bitcoin-predictor-2021-10-26-14-14-12-340/output/model.tar.gz',\n",
    "    role=role,\n",
    "    sagemaker_session = session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53843af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f324846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# create a predictor for BTC\n",
    "btc_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium',\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5723b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch latest BTC prices for evaluation of the model\n",
    "days_of_prices = 90\n",
    "\n",
    "def get_latest_btc_prices(): \n",
    "    response = requests.get('https://min-api.cryptocompare.com/data/v2/histoday?fsym=BTC&tsym=USD&limit={}'.format(days_of_prices - 1))\n",
    "    json_prices = json.loads(response.text)\n",
    "    return [ np.array([json_price['high'], json_price['low']]).mean() for json_price in json_prices['Data']['Data'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4727a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch latest prices\n",
    "latest_prices = get_latest_btc_prices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "add855ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create inference request with time series until 30 days ago\n",
    "def create_inference_request(latest_prices):\n",
    "    ts_start_timestamp = datetime.datetime.now() - datetime.timedelta(days=len(latest_prices))\n",
    "    ts_prices = latest_prices[:-prediction_length]\n",
    "    return { \n",
    "        \"instances\": [ { \"start\": ts_start_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"), \"target\": ts_prices } ],\n",
    "        \"configuration\": { \"num_samples\": 50, \"output_types\": [\"mean\", \"quantiles\", \"samples\"], \"quantiles\": [\"0.1\", \"0.5\", \"0.9\"] }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8013e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict prices\n",
    "request = create_inference_request(latest_prices)\n",
    "price_predictions = btc_predictor.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "00d84646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize prediction results and compare to real values\n",
    "\n",
    "def display_quantiles(price_predictions, actual_prices):\n",
    "    mean_predictions = price_predictions['predictions'][0]['mean']\n",
    "    quantile_10 = price_predictions['predictions'][0]['quantiles']['0.1']\n",
    "    quantile_50 = price_predictions['predictions'][0]['quantiles']['0.5']\n",
    "    quantile_90 = price_predictions['predictions'][0]['quantiles']['0.9']\n",
    "    days = len(actual_prices)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(range(days), actual_prices, label='actual prices')\n",
    "    plt.plot(range(days - 30, days), mean_predictions, label='mean predictions')\n",
    "    plt.fill_between(range(days - 30, days), quantile_10, quantile_90, color='b', alpha=.1, label='confidence interval')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Bitcoin Price [USD]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "display_quantiles(price_predictions, latest_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b7606299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bitcoin predictor scored an symmetric mean absolute percentage error of 5.55%\n"
     ]
    }
   ],
   "source": [
    "# calculate the symmetric mean absolute percentage error for comparison with the benchmarks\n",
    "\n",
    "def calculate_SMAPE(forecasts, actual_prices):\n",
    "    F = np.array(forecasts)\n",
    "    A = np.array(actual_prices)\n",
    "    n = len(forecasts)\n",
    "    smape = (100 / n) * np.sum( np.abs(F - A) / (np.abs(A) + np.abs(F)) )\n",
    "    return smape\n",
    "\n",
    "bitcoin_predictor_sMAPE = calculate_SMAPE(price_predictions['predictions'][0]['mean'], latest_prices[context_length:])\n",
    "\n",
    "print('The Bitcoin predictor scored an symmetric mean absolute percentage error of {:.2f}%'.format(bitcoin_predictor_sMAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ea8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70f1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5703c1a",
   "metadata": {},
   "source": [
    "## 4. Deployment and Web App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2562b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare code for AWS Lambda\n",
    "import boto3\n",
    "\n",
    "runtime= boto3.client('runtime.sagemaker')\n",
    "\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    return create_prediction_response()\n",
    "    \n",
    "    \n",
    "def create_prediction_response():\n",
    "    days_of_prices = 60\n",
    "    latest_prices = get_latest_btc_prices(days_of_prices)\n",
    "    inference_request = create_inference_request(latest_prices)\n",
    "\n",
    "    response = runtime.invoke_endpoint(EndpointName='forecasting-deepar-2021-10-29-06-44-53-190',\n",
    "                                       ContentType='application/json',\n",
    "                                       Body=inference_request)\n",
    "    response_json = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    \n",
    "    return format_response(response_json, latest_prices)\n",
    "    \n",
    "def get_latest_btc_prices(days_of_prices): \n",
    "    response = requests.get('https://min-api.cryptocompare.com/data/v2/histoday?fsym=BTC&tsym=USD&limit={}'.format(days_of_prices - 1))\n",
    "    json_prices = json.loads(response.text)\n",
    "    return [ np.array([json_price['high'], json_price['low']]).mean() for json_price in json_prices['Data']['Data'] ]\n",
    "\n",
    "def create_inference_request(latest_prices):\n",
    "    ts_start_timestamp = datetime.datetime.now() - datetime.timedelta(days=len(latest_prices))\n",
    "    return json.dumps({ \n",
    "        \"instances\": [ { \"start\": ts_start_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"), \"target\": latest_prices } ],\n",
    "        \"configuration\": { \"num_samples\": 50, \"output_types\": [\"mean\", \"quantiles\", \"samples\"], \"quantiles\": [\"0.1\", \"0.5\", \"0.9\"] }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fe31c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response, latest_prices): \n",
    "    mean_predictions = response['predictions'][0]['mean']\n",
    "    quantile_10 = response['predictions'][0]['quantiles']['0.1']\n",
    "    quantile_90 = response['predictions'][0]['quantiles']['0.9']\n",
    "    now = datetime.datetime.now()\n",
    "    historic_days = len(latest_prices)\n",
    "    prediction_days = len(mean_predictions)\n",
    "    \n",
    "    # add past prices\n",
    "    historic_timestamps = [(now - datetime.timedelta(days=historic_days - days)).strftime(\"%Y-%m-%d\") for days in range(historic_days)]\n",
    "    formated_response = [ {'x': historic_timestamps[day], 'y': latest_prices[day], 'group': 'historic'}  for day in range(historic_days)]\n",
    "    \n",
    "    # added latest actual price as prediction to have a nicer connection from current price to predictions in the graph\n",
    "    formated_response.append({'x': historic_timestamps[historic_days-1], 'y': latest_prices[historic_days-1], 'group': 'pred_median'})\n",
    "    \n",
    "    # add predictions with quantiles\n",
    "    prediction_timestamps = [(now + datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\") for days in range(prediction_days)]\n",
    "    for day in range(prediction_days):\n",
    "        formated_response.append({'x': prediction_timestamps[day], 'y': mean_predictions[day], 'group': 'pred_median'})\n",
    "    for day in range(prediction_days):\n",
    "        formated_response.append({'x': prediction_timestamps[day], 'y': quantile_10[day], 'group': 'pred_q10'})    \n",
    "    for day in range(prediction_days):\n",
    "        formated_response.append({'x': prediction_timestamps[day], 'y': quantile_90[day], 'group': 'pred_q90'})\n",
    "    \n",
    "    return formated_response\n",
    "\n",
    "result = create_prediction_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28aeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be9f69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16bf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d9002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
